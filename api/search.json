[{"id":"fe1f8fc0d1387355bca72fa308af9e3c","title":"容器技术实现基础和原理","content":"容器是 Paas（ Platform-as-a-Service，平台即服务）的一种体现。将所需软件整合成一个应用，一个服务。\n通俗的讲：容器是一种沙盒技术。把应用整体封装起来，应用与应用之间，在各自的边界内运行，不会相互干扰；并且封装起来的应用能够很容易的完成打包和分发。\n实现原理容器技术的核心就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。 所以，容器只是运行在宿主机上的一种特殊的进程，使用的还是同一个宿主机的操作系统内核。\n","slug":"容器化应用/容器技术实现基础和原理","date":"2021-03-31T01:49:48.000Z","categories_index":"k8s","tags_index":"docker,容器,liunx","author_index":"王小妖"},{"id":"58cd1de81cc6a83719721cae20d0ce2c","title":"HTTP3协议的深入剖析","content":"\n\n\n\n\n\n\n\n\n原文来自陶辉老师的《深入剖析HTTP3协议》,这里做一些转载和自己的记录,免得忘了\nHTTP3协议的深入剖析自2017年起HTTP3协议已发布了34个Draft，推出在即，Chrome、Nginx等软件都在跟进实现最新的草案。本文将介绍HTTP3协议规范、应用场景及实现原理。\n2015年HTTP2协议正式推出后，已经有接近一半的互联网站点在使用它：\n\nHTTP2协议虽然大幅提升了HTTP/1.1的性能，然而，基于TCP实现的HTTP2遗留下3个问题：\n\n有序字节流引出的 队头阻塞（Head-of-line blocking），使得HTTP2的多路复用能力大打折扣；\nTCP与TLS叠加了握手时延，建链时长还有1倍的下降空间；\n基于TCP四元组确定一个连接，这种诞生于有线网络的设计，并不适合移动状态下的无线网络，这意味着IP地址的频繁变动会导致TCP连接、TLS会话反复握手，成本高昂。\n\nHTTP3协议解决了这些问题：\n\nHTTP3基于UDP协议重新定义了连接，在QUIC层实现了无序、并发字节流的传输，解决了队头阻塞问题（包括基于QPACK解决了动态表的队头阻塞）；\nHTTP3重新定义了TLS协议加密QUIC头部的方式，既提高了网络攻击成本，又降低了建立连接的速度（仅需1个RTT就可以同时完成建链与密钥协商）；\nHTTP3 将Packet、QUIC Frame、HTTP3 Frame分离，实现了连接迁移功能，降低了5G环境下高速移动设备的连接维护成本。\n\nHTTP3协议到底是什么？就像HTTP2协议一样，HTTP3并没有改变HTTP1的语义。那什么是HTTP语义呢？在我看来，它包括以下3个点：\n\n请求只能由客户端发起，而服务器针对每个请求返回一个响应；\n请求与响应都由Header、Body（可选）组成，其中请求必须含有URL和方法，而响应必须含有响应码；\nHeader中各Name对应的含义保持不变。\n\nHTTP3在保持HTTP1语义不变的情况下，更改了编码格式，这由2个原因所致：\n首先，是为了减少编码长度。下图中HTTP1协议的编码使用了ASCII码，用空格、冒号以及\\r\\n作为分隔符，编码效率很低：\n\nHTTP2与HTTP3采用二进制、静态表、动态表与Huffman算法对HTTP Header编码，不只提供了高压缩率，还加快了发送端编码、接收端解码的速度。\n其次，由于HTTP1协议不支持多路复用，这样高并发只能通过多开一些TCP连接实现。然而，通过TCP实现高并发有3个弊端：\n\n实现成本高。TCP是由操作系统内核实现的，如果通过多线程实现并发，并发线程数不能太多，否则线程间切换成本会以指数级上升；如果通过异步、非阻塞socket实现并发，开发效率又太低；\n每个TCP连接与TLS会话都叠加了2-3个RTT的建链成本；\nTCP连接有一个防止出现拥塞的慢启动流程，它会对每个TCP连接都产生减速效果。\n\n因此，HTTP2与HTTP3都在应用层实现了多路复用功能\n\nHTTP2协议基于TCP有序字节流实现，因此应用层的多路复用并不能做到无序地并发，在丢包场景下会出现队头阻塞问题。如下面的动态图片所示，服务器返回的绿色响应由5个TCP报文组成，而黄色响应由4个TCP报文组成，当第2个黄色报文丢失后，即使客户端接收到完整的5个绿色报文，但TCP层不会允许应用进程的read函数读取到最后5个报文，并发成了一纸空谈：\n\n当网络繁忙时，丢包概率会很高，多路复用受到了很大限制。因此， HTTP3采用UDP作为传输层协议，重新实现了无序连接，并在此基础上通过有序的QUIC Stream提供了多路复用 ，如下图所示：\n\n最早这一实验性协议由Google推出，并命名为gQUIC，因此，IETF草案中仍然保留了QUIC概念，用来描述HTTP3协议的传输层和表示层。HTTP3协议规范由以下5个部分组成：\n\nQUIC层由https://tools.ietf.org/html/draft-ietf-quic-transport-29 描述，它定义了连接、报文的可靠传输、有序字节流的实现；\nTLS协议会将QUIC层的部分报文头部暴露在明文中，方便代理服务器进行路由。https://tools.ietf.org/html/draft-ietf-quic-tls-29 规范定义了QUIC与TLS的结合方式；\n丢包检测、RTO重传定时器预估等功能由https://tools.ietf.org/html/draft-ietf-quic-recovery-29 定义，目前拥塞控制使用了类似TCP New RENO的算法，未来有可能更换为基于带宽检测的算法（例如BBR）；\n基于以上3个规范，https://tools.ietf.org/html/draft-ietf-quic-http-29 定义了HTTP语义的实现，包括服务器推送、请求响应的传输等；\n在HTTP2中，由HPACK规范定义HTTP头部的压缩算法。由于HPACK动态表的更新具有时序性，无法满足HTTP3的要求。在HTTP3中，QPACK定义HTTP头部的编码：https://tools.ietf.org/html/draft-ietf-quic-qpack-16 。注意，以上规范的最新草案都到了29，而QPACK相对简单，它目前更新到16。\n\n自1991年诞生的HTTP/0.9协议已不再使用， 但1996推出的HTTP/1.0、1999年推出的HTTP/1.1、2015年推出的HTTP2协议仍然共存于互联网中（HTTP/1.0在企业内网中还在广为使用，例如Nginx与上游的默认协议还是1.0版本），即将面世的HTTP3协议的加入，将会进一步增加协议适配的复杂度 。\n连接迁移功能的实现对于当下的HTTP1和HTTP2协议，传输请求前需要先完成耗时1个RTT的TCP三次握手、耗时1个RTT的TLS握手（TLS1.3），由于它们分属内核实现的传输层、openssl库实现的表示层，所以难以合并在一起，如下图所示\n\n在IoT时代，移动设备接入的网络会频繁变动，从而导致设备IP地址改变。对于通过四元组（源IP、源端口、目的IP、目的端口）定位连接的TCP协议来说，这意味着连接需要断开重连，所以上述2个RTT的建链时延、TCP慢启动都需要重新来过。而HTTP3的QUIC层实现了连接迁移功能，允许移动设备更换IP地址后，只要仍保有上下文信息（比如连接ID、TLS密钥等），就可以复用原连接。\n在UDP报文头部与HTTP消息之间，共有3层头部，定义连接且实现了Connection Migration主要是在Packet Header中完成的，如下图所示：\n\n这3层Header实现的功能各不相同：\n\nPacket Header实现了可靠的连接。当UDP报文丢失后，通过Packet Header中的Packet Number实现报文重传。连接也是通过其中的Connection ID字段定义的；\nQUIC Frame Header在无序的Packet报文中，基于QUIC Stream概念实现了有序的字节流，这允许HTTP消息可以像在TCP连接上一样传输；\nHTTP3 Frame Header定义了HTTP Header、Body的格式，以及服务器推送、QPACK编解码流等功能。\n\n为了进一步提升网络传输效率，Packet Header又可以细分为两种：\n\nLong Packet Header用于首次建立连接；\nShort Packet Header用于日常传输数据。\n\n其中，Long Packet Header的格式如下图所示：\n\n建立连接时，连接是由服务器通过Source Connection ID字段分配的，这样，后续传输时，双方只需要固定住Destination Connection ID，就可以在客户端IP地址、端口变化后，绕过UDP四元组（与TCP四元组相同），实现连接迁移功能。下图是Short Packet Header头部的格式，这里就不再需要传输Source Connection ID字段了：\n\n上图中的Packet Number是每个报文独一无二的序号，基于它可以实现丢失报文的精准重发。如果你通过抓包观察Packet Header，会发现Packet Number被TLS层加密保护了，这是为了防范各类网络攻击的一种设计。下图给出了Packet Header中被加密保护的字段：\n\n其中，显示为E（Encrypt）的字段表示被TLS加密过。当然，Packet Header只是描述了最基本的连接信息，其上的Stream层、HTTP消息也是被加密保护的：\n\n现在我们已经对HTTP3协议的格式有了基本的了解，接下来我们通过队头阻塞问题，看看Packet之上的QUIC Frame、HTTP3 Frame帧格式。\nStream多路复用时的队头阻塞问题解决其实，解决队头阻塞的方案，就是允许微观上有序发出的Packet报文，在接收端无序到达后也可以应用于并发请求中。比如上文的动态图中，如果丢失的黄色报文对其后发出的绿色报文不造成影响，队头阻塞问题自然就得到了解决：\n\n在Packet Header之上的QUIC Frame Header，定义了有序字节流Stream，而且Stream之间可以实现真正的并发。HTTP3的Stream，借鉴了HTTP2中的部分概念，所以在讨论QUIC Frame Header格式之前，我们先来看看HTTP2中的Stream长成什么样子：\n\n每个Stream就像HTTP1中的TCP连接，它保证了承载的HEADERS frame（存放HTTP Header）、DATA frame（存放HTTP Body）是有序到达的，多个Stream之间可以并行传输。在HTTP3中，上图中的HTTP2 frame会被拆解为两层，我们先来看底层的QUIC Frame。\n一个Packet报文中可以存放多个QUIC Frame，当然所有Frame的长度之和不能大于PMTUD（Path Maximum Transmission Unit Discovery，这是大于1200字节的值），你可以把它与IP路由中的MTU概念对照理解：\n\n每一个Frame都有明确的类型：\n\n前4个字节的Frame Type字段描述的类型不同，接下来的编码也不相同，下表是各类Frame的16进制Type值\n\n\n\nValue\nName\nValue\nName\n\n\n\n0x00\nPADDING\n0x02 – 0x03\nACK\n\n\n0x01\nPING\n0x08 – 0x0f\nSTREAM\n\n\n0x04\nRESET_STREAM\n0x12-0x13\nMAX_STREAMS\n\n\n0x05\nSTOP_SENDING\n0x16-0x17\nSTREAM_BLOCKED\n\n\n0x06\nCRYPTO\n0x1c-0x1d\nCONNECTION_CLOSE\n\n\n0x07\nNEW_TOKEN\n0x11\nMAX_STREAM_DATA\n\n\n0x10\nMAX_DATA\n0x14\nDATA_BLOCKED\n\n\n0x15\nSTREAM_DATA_BLOCKED\n0x1a\nPATH_CHALLENGE\n\n\n0x18\nNEW_CONNECTION_ID\n0x1b\nPATH_RESPONSE\n\n\n0x19\nRETRY_CONNECTION_ID\n0x1e\nHANDSHAKE_DONE\n\n\n在上表中，我们只要分析0x08-0x0f这8种STREAM类型的Frame，就能弄明白Stream流的实现原理，自然也就清楚队头阻塞是怎样解决的了。Stream Frame用于传递HTTP消息，它的格式如下所示：\n\n可见，Stream Frame头部的3个字段，完成了多路复用、有序字节流以及报文段层面的二进制分隔功能，包括：\n\nStream ID标识了一个有序字节流。当HTTP Body非常大，需要跨越多个Packet时，只要在每个Stream Frame中含有同样的Stream ID，就可以传输任意长度的消息。多个并发传输的HTTP消息，通过不同的Stream ID加以区别；\n消息序列化后的“有序”特性，是通过Offset字段完成的，它类似于TCP协议中的Sequence序号，用于实现Stream内多个Frame间的累计确认功能；\nLength指明了Frame数据的长度。\n\n你可能会奇怪，为什么会有8种Stream Frame呢？这是因为0x08-0x0f 这8种类型其实是由3个二进制位组成，它们实现了以下3 标志位的组合：\n\n第1位表示是否含有Offset，当它为0时，表示这是Stream中的起始Frame，这也是上图中Offset是可选字段的原因；\n第2位表示是否含有Length字段；\n第3位Fin，表示这是Stream中最后1个Frame，与HTTP2协议Frame帧中的FIN标志位相同。\n\nStream数据中并不会直接存放HTTP消息，因为HTTP3还需要实现服务器推送、权重优先级设定、流量控制等功能，所以Stream Data中首先存放了HTTP3 Frame：\n\n其中，Length指明了HTTP消息的长度，而Type字段（请注意，低2位有特殊用途，在QPACK章节中会详细介绍）包含了以下类型：\n\n0x00：DATA帧，用于传输HTTP Body包体；\n0x01：HEADERS帧，通过QPACK 编码，传输HTTP Header头部；\n0x03：CANCEL_PUSH控制帧，用于取消1次服务器推送消息，通常客户端在收到PUSH_PROMISE帧后，通过它告知服务器不需要这次推送；\n0x04：SETTINGS控制帧，设置各类通讯参数；\n0x05：PUSH_PROMISE帧，用于服务器推送HTTP Body前，先将HTTP Header头部发给客户端，流程与HTTP2相似；\n0x07：GOAWAY控制帧，用于关闭连接（注意，不是关闭Stream）；\n0x0d：MAX_PUSH_ID，客户端用来限制服务器推送消息数量的控制帧。\n\n总结一下，QUIC Stream Frame定义了有序字节流，且多个Stream间的传输没有时序性要求，这样，HTTP消息基于QUIC Stream就实现了真正的多路复用，队头阻塞问题自然就被解决掉了。\nQPACK编码对对头阻塞队列问题的解决最后，我们再看下HTTP Header头部的编码方式，它需要面对另一种队头阻塞问题。\n与HTTP2中的HPACK编码方式相似，HTTP3中的QPACK也采用了静态表、动态表及Huffman编码：\n\n先来看静态表的变化。在上图中，GET方法映射为数字2，这是通过客户端、服务器协议实现层的硬编码完成的。在HTTP2中，共有61个静态表项：\n\n而在QPACK中，则上升为98个静态表项，比如Nginx上的ngx_htt_v3_static_table数组所示\n\n你也可以从这里找到完整的HTTP3静态表。对于Huffman以及整数的编码，QPACK与HPACK并无多大不同，但动态表编解码方式差距很大。\n所谓动态表，就是将未包含在静态表中的Header项，在其首次出现时加入动态表，这样后续传输时仅用1个数字表示，大大提升了编码效率。因此，动态表是天然具备时序性的，如果首次出现的请求出现了丢包，后续请求解码HPACK头部时，一定会被阻塞！\nQPACK是如何解决队头阻塞问题的呢？事实上，QPACK将动态表的编码、解码独立在单向Stream中传输，仅当单向Stream中的动态表编码成功后，接收端才能解码双向Stream上HTTP消息里的动态表索引。\n我们又引入了单向Stream和双向Stream概念，不要头疼，它其实很简单。单向指只有一端可以发送消息，双向则指两端都可以发送消息。还记得上一小节的QUIC Stream Frame头部吗？其中的Stream ID别有玄机，除了标识Stream外，它的低2位还可以表达以下组合：\n\n因此，当Stream ID是0、4、8、12时，这就是客户端发起的双向Stream（HTTP3不支持服务器发起双向Stream），它用于传输HTTP请求与响应。单向Stream有很多用途，所以它在数据前又多出一个Stream Type字段：\n\nStream Type有以下取值：\n\n0x00：控制Stream，传递各类Stream控制消息；\n0x01：服务器推送消息；\n0x02：用于编码QPACK动态表，比如面对不属于静态表的HTTP请求头部，客户端可以通过这个Stream发送动态表编码；\n0x03：用于通知编码端QPACK动态表的更新结果。\n\n由于HTTP3的STREAM之间是乱序传输的，因此，若先发送的编码Stream后到达，双向Stream中的QPACK头部就无法解码，此时传输HTTP消息的双向Stream就会进入Block阻塞状态（两端可以通过控制帧定义阻塞Stream的处理方式）。\n小节最后对本文内容做个小结。\n基于四元组定义连接并不适用于下一代IoT网络，HTTP3创造出Connection ID概念实现了连接迁移，通过融合传输层、表示层，既缩短了握手时长，也加密了传输层中的绝大部分字段，提升了网络安全性。\nHTTP3在Packet层保障了连接的可靠性，在QUIC Frame层实现了有序字节流，在HTTP3 Frame层实现了HTTP语义，这彻底解开了队头阻塞问题，真正实现了应用层的多路复用。\nQPACK使用独立的单向Stream分别传输动态表编码、解码信息，这样乱序、并发传输HTTP消息的Stream既不会出现队头阻塞，也能基于时序性大幅压缩HTTP Header的体积。\n文章来源和引用说明\n\n\n\n\n\n\n\n\n原文作者： 陶辉原文链接： https://www.taohui.tech/2021/02/04/网络协议/深入剖析HTTP3协议/\n","slug":"网络协议/应用层协议/HTTP3协议的深入剖析","date":"2021-03-24T03:55:05.000Z","categories_index":"网络协议","tags_index":"网络协议,HTTP协议,应用层","author_index":"王小妖"},{"id":"620c4776a0cfecee5672c023c9db244a","title":"支持亿级消息的IM系统模块设计","content":"支持亿级用户的IM系统模块设计现代实现的及时通讯系统一般由长连接和短连接配合使用进行实现，一般的实现架构即Connector和Service两个部分,分别对应长连接服务和短连接服务，长连接服务主要用于服务端对客户端的推送和新消息到达的通知，短连接服务主要用于客户端对于消息的拉取和离线(在线)消息的同步。当用户数据量增大时,其很容易就会出现以下的缺陷:\n\n复杂性高：每个模块服务包含的功能职责增多、模块的边界模糊、 依赖关系不清晰、 代码质量参差不齐、 混乱地堆砌在一起。\n可靠性缺失： 某个核心服务出现问题，例如死循环、内存溢出等， 可能会导致整个系统不能正常使用。\n拓展成本增大： 当用户体量增大时,部分服务功能会成为系统瓶颈,当进行服务扩容时,因为部分功能瓶颈的原因，就需要将整个服务进行拓展，带来不需要的成本开销。\n\n为此就需要对常见IM系统架构进行更加细化的服务拆分,以下就IM服务功能拆分提供参考\n\n\n技术指标\n高可靠：确保不丢消息；\n高可用：任意机房或者服务器挂掉，不影响服务；\n实时性：不管用户在哪里，在线用户消息在1秒内达到（我们实际是75%消息可以做到120ms）；\n有序性：确保用户消息的有序性，不会出现发送和接受的乱序。\n\n架构拆分当需要满足亿级用户量的IM架构时，需要将IM服务的进行更加精细化的服务拆分\n\n业务系统：服务及时通讯的业务逻辑\n信令系统：负责用户登录，用户在线状态的维护，以及在线用户的下行推送\n推送系统：负责消息的在线推送和离线推送\n持久化系统：负责消息和文件的存储和查询\n\n\n\n业务系统业务系统的详细来说在于专注处理IM相关的业务逻辑，主要使用短连接进行实现(HTTP协议)\n\n消息发送的鉴权和支持(optional)：客户端通过短连接发送消息\n维护用户数据：用户基本信息等\n维护好友关系：好友请求、好友列表、好友信息等\n维护群组信息：群创建、解散、成员管理等\n提供数据：在线消息(optional)、离线拉取、历史记录同步\n其它逻辑：比如通过存储和推送系统，存储消息和发送通知\n\n其功能和实际的架构可以根据具体的业务量和自身的系统架构进行更加细化的服务细分\n信令系统对于IM系统来说，是最主要和最核心的需求和职责，主要维护服务端与客户端的长连接(socket)，其主要职责包含以下3个部分\n维护用户在线状态当用户体量大时，需要建立大量的Socket连接和用户接入，为此单台机器是不能满足业务需求的，其落地和必然是集群化的服务，多台服务未用户提供连接服务。当用户A需要给用户B发送消息时,是需要知道用户B当前连接上了那个服务器上，然后通过该台服务器上的Socket连接向用户发送下行通知信息。\n下行通知数据下发与维护用户在线状态的职责相关，当用户在线的时，如果有其它用户给他发消息，就需要走在线的系统推送，直接将新消息告知到客户端，而不是走离线推送信息。\n业务协议内容的分发信令服务不只可以处理IM请求，也可以处理其它类型的业务请求。为了处理不同的业务，就需要有分发能力。一般来说会使用Protobuf定义下发的业务协议，其中可能会包括SVID(Service Id)或是CMD(Commond)字段来标识消息数据类型，用户通过该标识能表明当前业务包的功能(eg:心跳和连接授权、QoS、消息到达、用户特权变更等)并交由业务服务进行处理。\n这样不管用户有多少的业务或是多少的实现表达，客户端与服务器端仅需要维护一个Socket连接。\n信令服务的服务拆分信令系统为了实现以上这3个职责，同时要确保我们服务可平行扩展的能力和稳定性，在实际的技术实现上，我们实际上把信令服务分拆为3个服务模块。\n- 连接授权和维护(Login服务)\n\n主要负责维护用户长链接：\n\n客户端与服务器之间长连接的维护、长连接的连接认证、连接的心跳。用户完成业务模块的登陆操作后，会持有登陆完成后授权给用户Token或者相关凭证、Login服务会接受客户端的连接并对用户心跳包持有的Token进行验证、如果成功就将认证结果发送到Online服务，当授权验证不通过时,直接关闭该次连接。\nLogin对并发要求比较高，一般要支持TCP+UDP+Websocket几种方式，单服务可以做到10-250万之间。从服务稳定性角度触发，建议是控制VM的CPU/内存，单服务器以20-50万为合适。\nLogin服务器本身没有状态，任何一个Login服务断掉，客户端检测到以后重连另一个Login服务器并发送心跳包，对整体服务可靠性基本没有影响。\n- 在线信息的维护和同步(Online服务)\n\n主要负责维护用户的在线信息:\n\n当用户掉线或者根本不在线，Online服务里用户相关信息就是空\n当用户在线时，Online就能找到用户登录在哪个集群，哪个Login服务器上\n多个Login服务器会连接到Online，定期同步用户登录和离线信息，把用户状态信息存储在共有的存储服务中(Redis集群)。因此也是无状态的，任何一个Online服务挂掉，不影响整体服务能力。当集群规模不大，用户规模也不大时，Online服务也可以收到Login服务里去。\n当规模比较大，建议分拆出来，一方面简化Login的逻辑复杂度，同时避免写共有的存储服务的慢操作，在Login服务里。因为Login要同时处理50万以上的并发链接，不适合在循环里嵌入慢操作。\n- 协议的解析和业务的路由(Route服务)\n\n主要负责信令系统跟其它子系统的交互：\n\nRoute下接Login服务，可以接受用户业务信息（IM），也可以往用户推送下行消息。多个后端业务系统可以接入到Route，按照服务类型（SVID、CMD）注册。\nIM服务可以接入到Route, 注册SVID_IM或CMD_IM。这样Login接收到SVID=SVID_IM、或者CMD_IM的消息，转发给Route，Route就可以根据SVID转发给IM相关的服务。\nRoute只做转发，不处理具体的业务逻辑，因此也是无状态的。一个信令集群可以有多个Route服务，任何服务挂了不影响整体服务能力。\n推送系统接收服务端给用户发送下行消息的请求后，通过信令服务查询用户是否在线，如果在线走信令服务器进行在线推送，如果不在线走离线推送。\n推送服务可能出现大规模并发蜂拥，可能会触发亿级的TPS。为此可以用Kafka或其他消息中间件做削峰。具体的服务实现模块可主要由以下4个部分组成:\n\nPushProxy：接受服务端给用户发送的下行消息，写入消息中间件\n消息中间件(Kafka)：缓存推送服务消息并做削峰，并完成消息任务的推送\nPushServer：监听来自消息中间件的请求，消费消息，完成用的在线、离线状态的判断，调用PushWorker\nPushWorker：真正推送给信令或者APNS、Firebase、或其他推送平台\n\n因此除了中间件以外的每个服务都是无状态的、因此也可以实现平行拓展和容错，任何服务挂点都不会对整体服务可用性产生影响。\n持久化系统当用户数据产生后，必然是需要伴随消息的存储和持久化的，因此持久化系统主要负责消息的存储和查询，已实现离线消息的拉取、漫游等的相关附属功能。因为消息量巨大，对存储服务的并发能力和存储量要求巨大。为了平衡性能、空间和成本，存储服务按数据的热度进行了分级和区别对待。\n\n短期消息(7天)：存储在Redis里\n近期消息(1-3个月)：存储在Mysql里，以备用户实时查询\n历史信息：存储在HBase里，作为历史数据慢查询\n\n为了应对超大群的大量消息处理，存储服务在实际的技术实现上，也做了比较细的分拆\n具体的业务划分\n\nMsgProxy：负责接受业务系统的存储请求，写入消息中间件\n MsgWriter：从消息中间件获取写请求，按需写入Redis和Mysql\nMsgReader：接受用户的消息查询请求，从Redis，Mysql或者HBase读数据\n\n部署上可能是3-4个MsgProxy，后端可以对应15个左右的MsgWriter。MsgWriter是比较慢的，需要同时操作多个数据库，还要保证操作的原子性。\n","slug":"及时通讯/支持亿级用户的IM系统模块设计","date":"2021-03-23T02:04:23.000Z","categories_index":"及时通讯","tags_index":"及时通讯,系统架构","author_index":"王小妖"},{"id":"9f19cde10b918c008ebff1af093bc9fb","title":"IM系统的可靠性保障方案设计","content":"\n  6703f070ab98bb6294c4cf62ba6bef8a8f5504636ece03b0f3bc331c647c2adb\n  \n    \n      \n      \n        输入密码，查看文章\n      \n    \n  \n\n","slug":"及时通讯/IM系统的可靠性保障方案设计","date":"2021-03-23T01:06:55.000Z","categories_index":"及时通讯","tags_index":"及时通讯,系统架构","author_index":"王小妖"},{"id":"8056d3bc2de6e72a17ab19fd85e6d8cd","title":"高并发网络应用的关键-Unix系统下的五种IO模型","content":"Unix 中提供了五种 IO 模型，分别是阻塞式IO、非阻塞式IO、IO复用、信号驱动式IO、异步IO。\n一个IO操作通常包括两个阶段：\n\n等待数据准备好；\n从内核向进程复制数据；\n\n对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待分组到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。\n实际应用程序在系统调用完成上面的 2 步操作时，调用方式的阻塞、非阻塞，操作系统在处理应用程序请求时，处理方式的同步、异步处理的不同，可以分为 5 种 I/O 模型。\n*注：recvfrom 函数(经 Socket 接收数据)，这里把它视为系统调用\n\n\n","slug":"历史文档/Unix-IO-5-Model","date":"2020-11-22T11:15:20.000Z","categories_index":"Unix网络编程","tags_index":"Unix,IO","author_index":"王小妖"},{"id":"6e9936c6f3fa9647d90930ffd9a587a1","title":"Maven项目管理详细","content":"pom.xml 就像 Make 的 MakeFile、Ant 的 build.xml 一样，Maven 项目的核心是 pom.xml。POM( Project Object Model，项目对象模型 ) 定义了项目的基本信息，用于描述项目如何构建，声明项目依赖，等等。\n在版本号的说明  :  SNAPSHOT – 快照版本，ALPHA – 内侧版本，BETA – 公测版本，RELEASE – 稳定版本，GA – 正式发布\n\n\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  &lt;modelVersion>4.0.0&lt;/modelVersion>\n \n  &lt;!-- The Basics -->\n  &lt;groupId>...&lt;/groupId>\n  &lt;artifactId>...&lt;/artifactId>\n  &lt;version>...&lt;/version>\n  &lt;packaging>...&lt;/packaging>\n  &lt;dependencies>...&lt;/dependencies>\n  &lt;parent>...&lt;/parent>\n  &lt;dependencyManagement>...&lt;/dependencyManagement>\n  &lt;modules>...&lt;/modules>\n  &lt;properties>...&lt;/properties>\n \n  &lt;!-- Build Settings -->\n  &lt;build>...&lt;/build>\n  &lt;reporting>...&lt;/reporting>\n \n  &lt;!-- More Project Information -->\n  &lt;name>...&lt;/name>\n  &lt;description>...&lt;/description>\n  &lt;url>...&lt;/url>\n  &lt;inceptionYear>...&lt;/inceptionYear>\n  &lt;licenses>...&lt;/licenses>\n  &lt;organization>...&lt;/organization>\n  &lt;developers>...&lt;/developers>\n  &lt;contributors>...&lt;/contributors>\n \n  &lt;!-- Environment Settings -->\n  &lt;issueManagement>...&lt;/issueManagement>\n  &lt;ciManagement>...&lt;/ciManagement>\n  &lt;mailingLists>...&lt;/mailingLists>\n  &lt;scm>...&lt;/scm>\n  &lt;prerequisites>...&lt;/prerequisites>\n  &lt;repositories>...&lt;/repositories>\n  &lt;pluginRepositories>...&lt;/pluginRepositories>\n  &lt;distributionManagement>...&lt;/distributionManagement>\n  &lt;profiles>...&lt;/profiles>\n&lt;/project>\n\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"     \n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"     \nxsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0http://maven.apache.org/maven-v4_0_0.xsd\">     \n    &lt;!--父项目的坐标。如果项目中没有规定某个元素的值，那么父项目中的对应值即为项目的默认值。 坐标包括group ID，artifact ID和 version。-->    \n    &lt;parent>    \n     &lt;!--被继承的父项目的构件标识符-->    \n     &lt;artifactId/>    \n     &lt;!--被继承的父项目的全球唯一标识符-->    \n     &lt;groupId/>    \n     &lt;!--被继承的父项目的版本-->    \n     &lt;version/>    \n     &lt;!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。Maven首先在构建当前项目的地方寻找父项 目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。-->    \n     &lt;relativePath/>    \n &lt;/parent>    \n &lt;!--声明项目描述符遵循哪一个POM模型版本。模型本身的版本很少改变，虽然如此，但它仍然是必不可少的，这是为了当Maven引入了新的特性或者其他模型变更的时候，确保稳定性。-->       \n    &lt;modelVersion>4.0.0&lt;/modelVersion>     \n    &lt;!--项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.mycompany.app生成的相对路径为：/com/mycompany/app-->     \n    &lt;groupId>asia.banseon&lt;/groupId>     \n    &lt;!-- 构件的标识符，它和group ID一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的artifact ID和groupID；在某个 特定的group ID下，artifact ID也必须是唯一的。构件是项目产生的或使用的一个东西，Maven为项目产生的构件包括：JARs，源 码，二进制发布和WARs等。-->     \n    &lt;artifactId>banseon-maven2&lt;/artifactId>     \n    &lt;!--项目产生的构件类型，例如jar、war、ear、pom。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型-->     \n    &lt;packaging>jar&lt;/packaging>     \n    &lt;!--项目当前版本，格式为:主版本.次版本.增量版本-限定版本号-->     \n    &lt;version>1.0-SNAPSHOT&lt;/version>     \n    &lt;!--项目的名称, Maven产生的文档用-->     \n    &lt;name>banseon-maven&lt;/name>     \n    &lt;!--项目主页的URL, Maven产生的文档用-->     \n    &lt;url>http://www.baidu.com/banseon&lt;/url>     \n    &lt;!-- 项目的详细描述, Maven 产生的文档用。  当这个元素能够用HTML格式描述时（例如，CDATA中的文本会被解析器忽略，就可以包含HTML标 签）， 不鼓励使用纯文本描述。如果你需要修改产生的web站点的索引页面，你应该修改你自己的索引页文件，而不是调整这里的文档。-->     \n    &lt;description>A maven project to study maven.&lt;/description>     \n    &lt;!--描述了这个项目构建环境中的前提条件。-->    \n &lt;prerequisites>    \n  &lt;!--构建该项目或使用该插件所需要的Maven的最低版本-->    \n    &lt;maven/>    \n &lt;/prerequisites>    \n &lt;!--项目的问题管理系统(Bugzilla, Jira, Scarab,或任何你喜欢的问题管理系统)的名称和URL，本例为 jira-->     \n    &lt;issueManagement>    \n     &lt;!--问题管理系统（例如jira）的名字，-->     \n        &lt;system>jira&lt;/system>     \n        &lt;!--该项目使用的问题管理系统的URL-->    \n        &lt;url>http://jira.baidu.com/banseon&lt;/url>     \n    &lt;/issueManagement>     \n    &lt;!--项目持续集成信息-->    \n &lt;ciManagement>    \n  &lt;!--持续集成系统的名字，例如continuum-->    \n  &lt;system/>    \n  &lt;!--该项目使用的持续集成系统的URL（如果持续集成系统有web接口的话）。-->    \n  &lt;url/>    \n  &lt;!--构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告）-->    \n  &lt;notifiers>    \n   &lt;!--配置一种方式，当构建中断时，以该方式通知用户/开发者-->    \n   &lt;notifier>    \n    &lt;!--传送通知的途径-->    \n    &lt;type/>    \n    &lt;!--发生错误时是否通知-->    \n    &lt;sendOnError/>    \n    &lt;!--构建失败时是否通知-->    \n    &lt;sendOnFailure/>    \n    &lt;!--构建成功时是否通知-->    \n    &lt;sendOnSuccess/>    \n    &lt;!--发生警告时是否通知-->    \n    &lt;sendOnWarning/>    \n    &lt;!--不赞成使用。通知发送到哪里-->    \n    &lt;address/>    \n    &lt;!--扩展配置项-->    \n    &lt;configuration/>    \n   &lt;/notifier>    \n  &lt;/notifiers>    \n &lt;/ciManagement>    \n &lt;!--项目创建年份，4位数字。当产生版权信息时需要使用这个值。-->    \n    &lt;inceptionYear/>    \n    &lt;!--项目相关邮件列表信息-->     \n    &lt;mailingLists>    \n     &lt;!--该元素描述了项目相关的所有邮件列表。自动产生的网站引用这些信息。-->     \n        &lt;mailingList>     \n         &lt;!--邮件的名称-->    \n            &lt;name>Demo&lt;/name>     \n            &lt;!--发送邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建-->     \n            &lt;post>banseon@126.com&lt;/post>     \n            &lt;!--订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建-->     \n            &lt;subscribe>banseon@126.com&lt;/subscribe>     \n            &lt;!--取消订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建-->     \n            &lt;unsubscribe>banseon@126.com&lt;/unsubscribe>     \n            &lt;!--你可以浏览邮件信息的URL-->    \n            &lt;archive>http:/hi.baidu.com/banseon/demo/dev/&lt;/archive>     \n        &lt;/mailingList>     \n    &lt;/mailingLists>     \n    &lt;!--项目开发者列表-->     \n    &lt;developers>     \n     &lt;!--某个项目开发者的信息-->    \n        &lt;developer>     \n         &lt;!--SCM里项目开发者的唯一标识符-->    \n            &lt;id>HELLO WORLD&lt;/id>     \n            &lt;!--项目开发者的全名-->    \n            &lt;name>banseon&lt;/name>     \n            &lt;!--项目开发者的email-->    \n            &lt;email>banseon@126.com&lt;/email>     \n            &lt;!--项目开发者的主页的URL-->    \n            &lt;url/>    \n            &lt;!--项目开发者在项目中扮演的角色，角色元素描述了各种角色-->    \n            &lt;roles>     \n                &lt;role>Project Manager&lt;/role>     \n                &lt;role>Architect&lt;/role>     \n            &lt;/roles>    \n            &lt;!--项目开发者所属组织-->    \n            &lt;organization>demo&lt;/organization>     \n            &lt;!--项目开发者所属组织的URL-->    \n            &lt;organizationUrl>http://hi.baidu.com/banseon&lt;/organizationUrl>     \n            &lt;!--项目开发者属性，如即时消息如何处理等-->    \n            &lt;properties>     \n                &lt;dept>No&lt;/dept>     \n            &lt;/properties>    \n            &lt;!--项目开发者所在时区， -11到12范围内的整数。-->    \n            &lt;timezone>-5&lt;/timezone>     \n        &lt;/developer>     \n    &lt;/developers>     \n    &lt;!--项目的其他贡献者列表-->     \n    &lt;contributors>    \n     &lt;!--项目的其他贡献者。参见developers/developer元素-->    \n     &lt;contributor>    \n   &lt;name/>&lt;email/>&lt;url/>&lt;organization/>&lt;organizationUrl/>&lt;roles/>&lt;timezone/>&lt;properties/>    \n     &lt;/contributor>         \n    &lt;/contributors>       \n    &lt;!--该元素描述了项目所有License列表。 应该只列出该项目的license列表，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。-->     \n    &lt;licenses>    \n     &lt;!--描述了项目的license，用于生成项目的web站点的license页面，其他一些报表和validation也会用到该元素。-->     \n        &lt;license>    \n         &lt;!--license用于法律上的名称-->    \n            &lt;name>Apache 2&lt;/name>     \n            &lt;!--官方的license正文页面的URL-->    \n            &lt;url>http://www.baidu.com/banseon/LICENSE-2.0.txt&lt;/url>     \n            &lt;!--项目分发的主要方式：    \n              repo，可以从Maven库下载    \n              manual， 用户必须手动下载和安装依赖-->    \n            &lt;distribution>repo&lt;/distribution>     \n            &lt;!--关于license的补充信息-->    \n            &lt;comments>A business-friendly OSS license&lt;/comments>     \n        &lt;/license>     \n    &lt;/licenses>     \n    &lt;!--SCM(Source Control Management)标签允许你配置你的代码库，供Maven web站点和其它插件使用。-->     \n    &lt;scm>     \n        &lt;!--SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。-->     \n        &lt;connection>     \n            scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk)      \n        &lt;/connection>     \n        &lt;!--给开发者使用的，类似connection元素。即该连接不仅仅只读-->    \n        &lt;developerConnection>     \n            scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk      \n        &lt;/developerConnection>    \n        &lt;!--当前代码的标签，在开发阶段默认为HEAD-->    \n        &lt;tag/>           \n        &lt;!--指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。-->     \n        &lt;url>http://svn.baidu.com/banseon&lt;/url>     \n    &lt;/scm>     \n    &lt;!--描述项目所属组织的各种属性。Maven产生的文档用-->     \n    &lt;organization>     \n     &lt;!--组织的全名-->    \n        &lt;name>demo&lt;/name>     \n        &lt;!--组织主页的URL-->    \n        &lt;url>http://www.baidu.com/banseon&lt;/url>     \n    &lt;/organization>    \n    &lt;!--构建项目需要的信息-->    \n    &lt;build>    \n     &lt;!--该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。-->    \n  &lt;sourceDirectory/>    \n  &lt;!--该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。-->    \n  &lt;scriptSourceDirectory/>    \n  &lt;!--该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。-->    \n  &lt;testSourceDirectory/>    \n  &lt;!--被编译过的应用程序class文件存放的目录。-->    \n  &lt;outputDirectory/>    \n  &lt;!--被编译过的测试class文件存放的目录。-->    \n  &lt;testOutputDirectory/>    \n  &lt;!--使用来自该项目的一系列构建扩展-->    \n  &lt;extensions>    \n   &lt;!--描述使用到的构建扩展。-->    \n   &lt;extension>    \n    &lt;!--构建扩展的groupId-->    \n    &lt;groupId/>    \n    &lt;!--构建扩展的artifactId-->    \n    &lt;artifactId/>    \n    &lt;!--构建扩展的版本-->    \n    &lt;version/>    \n   &lt;/extension>    \n  &lt;/extensions>    \n  &lt;!--当项目没有规定目标（Maven2 叫做阶段）时的默认值-->    \n  &lt;defaultGoal/>    \n  &lt;!--这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。-->    \n  &lt;resources>    \n   &lt;!--这个元素描述了项目相关或测试相关的所有资源路径-->    \n   &lt;resource>    \n    &lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如$&#123;project.build.outputDirectory&#125;）。举个例 子，如果你想资源在特定的包里(org.apache.maven.messages)，你就必须该元素设置为org/apache/maven /messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。-->    \n    &lt;targetPath/>    \n    &lt;!--是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。-->    \n    &lt;filtering/>    \n    &lt;!--描述存放资源的目录，该路径相对POM路径-->    \n    &lt;directory/>    \n    &lt;!--包含的模式列表，例如**/*.xml.-->    \n    &lt;includes/>    \n    &lt;!--排除的模式列表，例如**/*.xml-->    \n    &lt;excludes/>    \n   &lt;/resource>    \n  &lt;/resources>    \n  &lt;!--这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。-->    \n  &lt;testResources>    \n   &lt;!--这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明-->    \n   &lt;testResource>    \n    &lt;targetPath/>&lt;filtering/>&lt;directory/>&lt;includes/>&lt;excludes/>    \n   &lt;/testResource>    \n  &lt;/testResources>    \n  &lt;!--构建产生的所有文件存放的目录-->    \n  &lt;directory/>    \n  &lt;!--产生的构件的文件名，默认值是$&#123;artifactId&#125;-$&#123;version&#125;。-->    \n  &lt;finalName/>    \n  &lt;!--当filtering开关打开时，使用到的过滤器属性文件列表-->    \n  &lt;filters/>    \n  &lt;!--子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置-->    \n  &lt;pluginManagement>    \n   &lt;!--使用的插件列表 。-->    \n   &lt;plugins>    \n    &lt;!--plugin元素包含描述插件所需要的信息。-->    \n    &lt;plugin>    \n     &lt;!--插件在仓库里的group ID-->    \n     &lt;groupId/>    \n     &lt;!--插件在仓库里的artifact ID-->    \n     &lt;artifactId/>    \n     &lt;!--被使用的插件的版本（或版本范围）-->    \n     &lt;version/>    \n     &lt;!--是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。-->    \n     &lt;extensions/>    \n     &lt;!--在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。-->    \n     &lt;executions>    \n      &lt;!--execution元素包含了插件执行需要的信息-->    \n      &lt;execution>    \n       &lt;!--执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标-->    \n       &lt;id/>    \n       &lt;!--绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段-->    \n       &lt;phase/>    \n       &lt;!--配置的执行目标-->    \n       &lt;goals/>    \n       &lt;!--配置是否被传播到子POM-->    \n       &lt;inherited/>    \n       &lt;!--作为DOM对象的配置-->    \n       &lt;configuration/>    \n      &lt;/execution>    \n     &lt;/executions>    \n     &lt;!--项目引入插件所需要的额外依赖-->    \n     &lt;dependencies>    \n      &lt;!--参见dependencies/dependency元素-->    \n      &lt;dependency>    \n       ......    \n      &lt;/dependency>    \n     &lt;/dependencies>         \n     &lt;!--任何配置是否被传播到子项目-->    \n     &lt;inherited/>    \n     &lt;!--作为DOM对象的配置-->    \n     &lt;configuration/>    \n    &lt;/plugin>    \n   &lt;/plugins>    \n  &lt;/pluginManagement>    \n  &lt;!--使用的插件列表-->    \n  &lt;plugins>    \n   &lt;!--参见build/pluginManagement/plugins/plugin元素-->    \n   &lt;plugin>    \n    &lt;groupId/>&lt;artifactId/>&lt;version/>&lt;extensions/>    \n    &lt;executions>    \n     &lt;execution>    \n      &lt;id/>&lt;phase/>&lt;goals/>&lt;inherited/>&lt;configuration/>    \n     &lt;/execution>    \n    &lt;/executions>    \n    &lt;dependencies>    \n     &lt;!--参见dependencies/dependency元素-->    \n     &lt;dependency>    \n      ......    \n     &lt;/dependency>    \n    &lt;/dependencies>    \n    &lt;goals/>&lt;inherited/>&lt;configuration/>    \n   &lt;/plugin>    \n  &lt;/plugins>    \n &lt;/build>    \n &lt;!--在列的项目构建profile，如果被激活，会修改构建处理-->    \n &lt;profiles>    \n  &lt;!--根据环境参数或命令行参数激活某个构建处理-->    \n  &lt;profile>    \n   &lt;!--构建配置的唯一标识符。即用于命令行激活，也用于在继承时合并具有相同标识符的profile。-->    \n   &lt;id/>    \n   &lt;!--自动触发profile的条件逻辑。Activation是profile的开启钥匙。profile的力量来自于它    \n   能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。-->    \n   &lt;activation>    \n    &lt;!--profile默认是否激活的标志-->    \n    &lt;activeByDefault/>    \n    &lt;!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。-->    \n    &lt;jdk/>    \n    &lt;!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。-->    \n    &lt;os>    \n     &lt;!--激活profile的操作系统的名字-->    \n     &lt;name>Windows XP&lt;/name>    \n     &lt;!--激活profile的操作系统所属家族(如 'windows')-->    \n     &lt;family>Windows&lt;/family>    \n     &lt;!--激活profile的操作系统体系结构 -->    \n     &lt;arch>x86&lt;/arch>    \n     &lt;!--激活profile的操作系统版本-->    \n     &lt;version>5.1.2600&lt;/version>    \n    &lt;/os>    \n    &lt;!--如果Maven检测到某一个属性（其值可以在POM中通过$&#123;名称&#125;引用），其拥有对应的名称和值，Profile就会被激活。如果值    \n    字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段-->    \n    &lt;property>    \n     &lt;!--激活profile的属性的名称-->    \n     &lt;name>mavenVersion&lt;/name>    \n     &lt;!--激活profile的属性的值-->    \n     &lt;value>2.0.3&lt;/value>    \n    &lt;/property>    \n    &lt;!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活    \n    profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。-->    \n    &lt;file>    \n     &lt;!--如果指定的文件存在，则激活profile。-->    \n     &lt;exists>/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/exists>    \n     &lt;!--如果指定的文件不存在，则激活profile。-->    \n     &lt;missing>/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/missing>    \n    &lt;/file>    \n   &lt;/activation>    \n   &lt;!--构建项目所需要的信息。参见build元素-->    \n   &lt;build>    \n    &lt;defaultGoal/>    \n    &lt;resources>    \n     &lt;resource>    \n      &lt;targetPath/>&lt;filtering/>&lt;directory/>&lt;includes/>&lt;excludes/>    \n     &lt;/resource>    \n    &lt;/resources>    \n    &lt;testResources>    \n     &lt;testResource>    \n      &lt;targetPath/>&lt;filtering/>&lt;directory/>&lt;includes/>&lt;excludes/>    \n     &lt;/testResource>    \n    &lt;/testResources>    \n    &lt;directory/>&lt;finalName/>&lt;filters/>    \n    &lt;pluginManagement>    \n     &lt;plugins>    \n      &lt;!--参见build/pluginManagement/plugins/plugin元素-->    \n      &lt;plugin>    \n       &lt;groupId/>&lt;artifactId/>&lt;version/>&lt;extensions/>    \n       &lt;executions>    \n        &lt;execution>    \n         &lt;id/>&lt;phase/>&lt;goals/>&lt;inherited/>&lt;configuration/>    \n        &lt;/execution>    \n       &lt;/executions>    \n       &lt;dependencies>    \n        &lt;!--参见dependencies/dependency元素-->    \n        &lt;dependency>    \n         ......    \n        &lt;/dependency>    \n       &lt;/dependencies>    \n       &lt;goals/>&lt;inherited/>&lt;configuration/>    \n      &lt;/plugin>    \n     &lt;/plugins>    \n    &lt;/pluginManagement>    \n    &lt;plugins>    \n     &lt;!--参见build/pluginManagement/plugins/plugin元素-->    \n     &lt;plugin>    \n      &lt;groupId/>&lt;artifactId/>&lt;version/>&lt;extensions/>    \n      &lt;executions>    \n       &lt;execution>    \n        &lt;id/>&lt;phase/>&lt;goals/>&lt;inherited/>&lt;configuration/>    \n       &lt;/execution>    \n      &lt;/executions>    \n      &lt;dependencies>    \n       &lt;!--参见dependencies/dependency元素-->    \n       &lt;dependency>    \n        ......    \n       &lt;/dependency>    \n      &lt;/dependencies>    \n      &lt;goals/>&lt;inherited/>&lt;configuration/>    \n     &lt;/plugin>    \n    &lt;/plugins>    \n   &lt;/build>    \n   &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径-->    \n   &lt;modules/>    \n   &lt;!--发现依赖和扩展的远程仓库列表。-->    \n   &lt;repositories>    \n    &lt;!--参见repositories/repository元素-->    \n    &lt;repository>    \n     &lt;releases>    \n      &lt;enabled/>&lt;updatePolicy/>&lt;checksumPolicy/>    \n     &lt;/releases>    \n     &lt;snapshots>    \n      &lt;enabled/>&lt;updatePolicy/>&lt;checksumPolicy/>    \n     &lt;/snapshots>    \n     &lt;id/>&lt;name/>&lt;url/>&lt;layout/>    \n    &lt;/repository>    \n   &lt;/repositories>    \n   &lt;!--发现插件的远程仓库列表，这些插件用于构建和报表-->    \n   &lt;pluginRepositories>    \n    &lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素-->        \n    &lt;pluginRepository>    \n     &lt;releases>    \n      &lt;enabled/>&lt;updatePolicy/>&lt;checksumPolicy/>    \n     &lt;/releases>    \n     &lt;snapshots>    \n      &lt;enabled/>&lt;updatePolicy/>&lt;checksumPolicy/>    \n     &lt;/snapshots>    \n     &lt;id/>&lt;name/>&lt;url/>&lt;layout/>    \n    &lt;/pluginRepository>    \n   &lt;/pluginRepositories>    \n   &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。-->    \n   &lt;dependencies>    \n    &lt;!--参见dependencies/dependency元素-->    \n    &lt;dependency>    \n     ......    \n    &lt;/dependency>    \n   &lt;/dependencies>    \n   &lt;!--不赞成使用. 现在Maven忽略该元素.-->    \n   &lt;reports/>       \n   &lt;!--该元素包括使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。参见reporting元素-->    \n   &lt;reporting>    \n    ......    \n   &lt;/reporting>    \n   &lt;!--参见dependencyManagement元素-->    \n   &lt;dependencyManagement>    \n    &lt;dependencies>    \n     &lt;!--参见dependencies/dependency元素-->    \n     &lt;dependency>    \n      ......    \n     &lt;/dependency>    \n    &lt;/dependencies>    \n   &lt;/dependencyManagement>    \n   &lt;!--参见distributionManagement元素-->    \n   &lt;distributionManagement>    \n    ......    \n   &lt;/distributionManagement>    \n   &lt;!--参见properties元素-->    \n   &lt;properties/>    \n  &lt;/profile>    \n &lt;/profiles>    \n &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径-->    \n &lt;modules/>    \n    &lt;!--发现依赖和扩展的远程仓库列表。-->     \n    &lt;repositories>     \n     &lt;!--包含需要连接到远程仓库的信息-->    \n        &lt;repository>    \n         &lt;!--如何处理远程仓库里发布版本的下载-->    \n         &lt;releases>    \n          &lt;!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 -->    \n    &lt;enabled/>    \n    &lt;!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。-->    \n    &lt;updatePolicy/>    \n    &lt;!--当Maven验证构件校验文件失败时该怎么做：ignore（忽略），fail（失败），或者warn（警告）。-->    \n    &lt;checksumPolicy/>    \n   &lt;/releases>    \n   &lt;!-- 如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的 策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 -->    \n   &lt;snapshots>    \n    &lt;enabled/>&lt;updatePolicy/>&lt;checksumPolicy/>    \n   &lt;/snapshots>    \n   &lt;!--远程仓库唯一标识符。可以用来匹配在settings.xml文件里配置的远程仓库-->    \n   &lt;id>banseon-repository-proxy&lt;/id>     \n   &lt;!--远程仓库名称-->    \n            &lt;name>banseon-repository-proxy&lt;/name>     \n            &lt;!--远程仓库URL，按protocol://hostname/path形式-->    \n            &lt;url>http://192.168.1.169:9999/repository/&lt;/url>     \n            &lt;!-- 用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然 而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。-->    \n            &lt;layout>default&lt;/layout>               \n        &lt;/repository>     \n    &lt;/repositories>    \n    &lt;!--发现插件的远程仓库列表，这些插件用于构建和报表-->    \n    &lt;pluginRepositories>    \n     &lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素-->    \n  &lt;pluginRepository>    \n   ......    \n  &lt;/pluginRepository>    \n &lt;/pluginRepositories>    \n       \n    &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。-->     \n    &lt;dependencies>     \n        &lt;dependency>    \n   &lt;!--依赖的group ID-->    \n            &lt;groupId>org.apache.maven&lt;/groupId>     \n            &lt;!--依赖的artifact ID-->    \n            &lt;artifactId>maven-artifact&lt;/artifactId>     \n            &lt;!--依赖的版本号。 在Maven 2里, 也可以配置成版本号的范围。-->    \n            &lt;version>3.8.1&lt;/version>     \n            &lt;!-- 依赖类型，默认类型是jar。它通常表示依赖的文件的扩展名，但也有例外。一个类型可以被映射成另外一个扩展名或分类器。类型经常和使用的打包方式对应， 尽管这也有例外。一些类型的例子：jar，war，ejb-client和test-jar。如果设置extensions为 true，就可以在 plugin里定义新的类型。所以前面的类型的例子不完整。-->    \n            &lt;type>jar&lt;/type>    \n            &lt;!-- 依赖的分类器。分类器可以区分属于同一个POM，但不同构建方式的构件。分类器名被附加到文件名的版本号后面。例如，如果你想要构建两个单独的构件成 JAR，一个使用Java 1.4编译器，另一个使用Java 6编译器，你就可以使用分类器来生成两个单独的JAR构件。-->    \n            &lt;classifier>&lt;/classifier>    \n            &lt;!--依赖范围。在项目发布过程中，帮助决定哪些构件被包括进来。欲知详情请参考依赖机制。    \n                - compile ：默认范围，用于编译      \n                - provided：类似于编译，但支持你期待jdk或者容器提供，类似于classpath      \n                - runtime: 在执行时需要使用      \n                - test:    用于test任务时使用      \n                - system: 需要外在提供相应的元素。通过systemPath来取得      \n                - systemPath: 仅用于范围为system。提供相应的路径      \n                - optional:   当项目自身被依赖时，标注依赖是否传递。用于连续依赖时使用-->     \n            &lt;scope>test&lt;/scope>       \n            &lt;!--仅供system范围使用。注意，不鼓励使用这个元素，并且在新的版本中该元素可能被覆盖掉。该元素为依赖规定了文件系统上的路径。需要绝对路径而不是相对路径。推荐使用属性匹配绝对路径，例如$&#123;java.home&#125;。-->    \n            &lt;systemPath>&lt;/systemPath>     \n            &lt;!--当计算传递依赖时， 从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题-->    \n            &lt;exclusions>    \n             &lt;exclusion>     \n                    &lt;artifactId>spring-core&lt;/artifactId>     \n                    &lt;groupId>org.springframework&lt;/groupId>     \n                &lt;/exclusion>     \n            &lt;/exclusions>       \n            &lt;!--可选依赖，如果你在项目B中把C依赖声明为可选，你就需要在依赖于B的项目（例如项目A）中显式的引用对C的依赖。可选依赖阻断依赖的传递性。-->     \n            &lt;optional>true&lt;/optional>    \n        &lt;/dependency>    \n    &lt;/dependencies>    \n    &lt;!--不赞成使用. 现在Maven忽略该元素.-->    \n    &lt;reports>&lt;/reports>    \n    &lt;!--该元素描述使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。-->    \n &lt;reporting>    \n  &lt;!--true，则，网站不包括默认的报表。这包括“项目信息”菜单中的报表。-->    \n  &lt;excludeDefaults/>    \n  &lt;!--所有产生的报表存放到哪里。默认值是$&#123;project.build.directory&#125;/site。-->    \n  &lt;outputDirectory/>    \n  &lt;!--使用的报表插件和他们的配置。-->    \n  &lt;plugins>    \n   &lt;!--plugin元素包含描述报表插件需要的信息-->    \n   &lt;plugin>    \n    &lt;!--报表插件在仓库里的group ID-->    \n    &lt;groupId/>    \n    &lt;!--报表插件在仓库里的artifact ID-->    \n    &lt;artifactId/>    \n    &lt;!--被使用的报表插件的版本（或版本范围）-->    \n    &lt;version/>    \n    &lt;!--任何配置是否被传播到子项目-->    \n    &lt;inherited/>    \n    &lt;!--报表插件的配置-->    \n    &lt;configuration/>    \n    &lt;!--一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标-->    \n    &lt;reportSets>    \n     &lt;!--表示报表的一个集合，以及产生该集合的配置-->    \n     &lt;reportSet>    \n      &lt;!--报表集合的唯一标识符，POM继承时用到-->    \n      &lt;id/>    \n      &lt;!--产生报表集合时，被使用的报表的配置-->    \n      &lt;configuration/>    \n      &lt;!--配置是否被继承到子POMs-->    \n      &lt;inherited/>    \n      &lt;!--这个集合里使用到哪些报表-->    \n      &lt;reports/>    \n     &lt;/reportSet>    \n    &lt;/reportSets>    \n   &lt;/plugin>    \n  &lt;/plugins>    \n &lt;/reporting>    \n &lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和 artifact ID信息），如果group ID和artifact ID以外的一些信息没有描述，则通过group ID和artifact ID 匹配到这里的依赖，并使用这里的依赖信息。-->    \n &lt;dependencyManagement>    \n  &lt;dependencies>    \n   &lt;!--参见dependencies/dependency元素-->    \n   &lt;dependency>    \n    ......    \n   &lt;/dependency>    \n  &lt;/dependencies>    \n &lt;/dependencyManagement>       \n    &lt;!--项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。-->     \n    &lt;distributionManagement>    \n        &lt;!--部署项目产生的构件到远程仓库需要的信息-->    \n        &lt;repository>    \n         &lt;!--是分配给快照一个唯一的版本号（由时间戳和构建流水号）？还是每次都使用相同的版本号？参见repositories/repository元素-->    \n   &lt;uniqueVersion/>    \n   &lt;id>banseon-maven2&lt;/id>     \n   &lt;name>banseon maven2&lt;/name>     \n            &lt;url>file://$&#123;basedir&#125;/target/deploy&lt;/url>     \n            &lt;layout/>    \n  &lt;/repository>    \n  &lt;!--构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素-->     \n  &lt;snapshotRepository>    \n   &lt;uniqueVersion/>    \n   &lt;id>banseon-maven2&lt;/id>    \n            &lt;name>Banseon-maven2 Snapshot Repository&lt;/name>    \n            &lt;url>scp://svn.baidu.com/banseon:/usr/local/maven-snapshot&lt;/url>     \n   &lt;layout/>    \n  &lt;/snapshotRepository>    \n  &lt;!--部署项目的网站需要的信息-->     \n        &lt;site>    \n         &lt;!--部署位置的唯一标识符，用来匹配站点和settings.xml文件里的配置-->     \n            &lt;id>banseon-site&lt;/id>     \n            &lt;!--部署位置的名称-->    \n            &lt;name>business api website&lt;/name>     \n            &lt;!--部署位置的URL，按protocol://hostname/path形式-->    \n            &lt;url>     \n                scp://svn.baidu.com/banseon:/var/www/localhost/banseon-web      \n            &lt;/url>     \n        &lt;/site>    \n  &lt;!--项目下载页面的URL。如果没有该元素，用户应该参考主页。使用该元素的原因是：帮助定位那些不在仓库里的构件（由于license限制）。-->    \n  &lt;downloadUrl/>    \n  &lt;!--如果构件有了新的group ID和artifact ID（构件移到了新的位置），这里列出构件的重定位信息。-->    \n  &lt;relocation>    \n   &lt;!--构件新的group ID-->    \n   &lt;groupId/>    \n   &lt;!--构件新的artifact ID-->    \n   &lt;artifactId/>    \n   &lt;!--构件新的版本号-->    \n   &lt;version/>    \n   &lt;!--显示给用户的，关于移动的额外信息，例如原因。-->    \n   &lt;message/>    \n  &lt;/relocation>    \n  &lt;!-- 给出该构件在远程仓库的状态。不得在本地项目中设置该元素，因为这是工具自动更新的。有效的值有：none（默认），converted（仓库管理员从 Maven 1 POM转换过来），partner（直接从伙伴Maven 2仓库同步过来），deployed（从Maven 2实例部 署），verified（被核实时正确的和最终的）。-->    \n  &lt;status/>           \n    &lt;/distributionManagement>    \n    &lt;!--以值替代名称，Properties可以在整个POM中使用，也可以作为触发条件（见settings.xml配置文件里activation元素的说明）。格式是&lt;name>value&lt;/name>。-->    \n    &lt;properties/>    \n&lt;/project>    ","slug":"历史文档/Maven-XML-Details","date":"2020-11-13T10:24:35.000Z","categories_index":"maven","tags_index":"maven","author_index":"王小妖"},{"id":"2ee77e34c0e7f66f6f5d9526faba3817","title":"Liuns系统高效文件处理三剑客-Grep/Awk/Sed","content":"\n\n\n\n\n\n\n\n\n子曰：“工欲善其事，必先利其器。居是邦也，事其大夫之贤者，友其士之仁者。” –论语·卫灵公\nGrepGrep(global search regular expression(RE) and print out the line)是一款强大的文本搜索工具，支持正则表达式。来自Unix文本编辑器ed类似操作的命令,最初用于Unix操作系统的命令行工具。在给出文件列表或标准输入后，grep会对匹配一个或多个正则表达式的文本进行搜索，并只输出匹配（或者不匹配）的行或文本。\n[root@Leonardo-iWzl-Aliyun-Service ~]# grep --help\n用法: grep [选项]... PATTERN [FILE]...\nSearch for PATTERN in each FILE.\nExample: grep -i &#39;hello world&#39; menu.h main.c\n\n\nPattern selection and interpretation:\n  -E, --extended-regexp     PATTERN is an extended regular expression\n  -F, --fixed-strings       PATTERN is a set of newline-separated strings\n  -G, --basic-regexp        PATTERN is a basic regular expression (default)\n  -P, --perl-regexp         PATTERN is a Perl regular expression\n  -e, --regexp&#x3D;PATTERN      用 PATTERN 来进行匹配操作\n  -f, --file&#x3D;FILE           从 FILE 中取得 PATTERN\n  -i, --ignore-case         忽略大小写\n  -w, --word-regexp         强制 PATTERN 仅完全匹配字词\n  -x, --line-regexp         强制 PATTERN 仅完全匹配一行\n  -z, --null-data           一个 0 字节的数据行，但不是空行\n\n杂项:\n  -s, --no-messages         不显示错误信息\n  -v, --invert-match        选中不匹配的行\n  -V, --version             显示版本信息并退出\n      --help                显示此帮助并退出\n\nOutput control:\n  -m, --max-count&#x3D;NUM       stop after NUM selected lines\n  -b, --byte-offset         print the byte offset with output lines\n  -n, --line-number         print line number with output lines\n      --line-buffered       flush output on every line\n  -H, --with-filename       print file name with output lines\n  -h, --no-filename         suppress the file name prefix on output\n      --label&#x3D;LABEL         use LABEL as the standard input file name prefix\n  -o, --only-matching       只显示匹配PATTERN 部分的行\n  -q, --quiet, --silent     不显示所有常规输出\n      --binary-files&#x3D;TYPE   设定二进制文件的TYPE 类型；\n                            TYPE 可以是&#96;binary&#39;, &#96;text&#39;, 或&#96;without-match&#39;\n  -a, --text                等同于 --binary-files&#x3D;text\n  -I                        equivalent to --binary-files&#x3D;without-match\n  -d, --directories&#x3D;ACTION  how to handle directories;\n                            ACTION is &#39;read&#39;, &#39;recurse&#39;, or &#39;skip&#39;\n  -D, --devices&#x3D;ACTION      how to handle devices, FIFOs and sockets;\n                            ACTION is &#39;read&#39; or &#39;skip&#39;\n  -r, --recursive           like --directories&#x3D;recurse\n  -R, --dereference-recursive\n                            likewise, but follow all symlinks\n      --include&#x3D;FILE_PATTERN\n                            search only files that match FILE_PATTERN\n      --exclude&#x3D;FILE_PATTERN\n                            skip files and directories matching FILE_PATTERN\n      --exclude-from&#x3D;FILE   skip files matching any file pattern from FILE\n      --exclude-dir&#x3D;PATTERN directories that match PATTERN will be skipped.\n  -L, --files-without-match print only names of FILEs with no selected lines\n  -l, --files-with-matches  print only names of FILEs with selected lines\n  -c, --count               print only a count of selected lines per FILE\n\n文件控制:\n  -B, --before-context&#x3D;NUM  打印文本及其前面NUM 行\n  -A, --after-context&#x3D;NUM   打印文本及其后面NUM 行\n  -C, --context&#x3D;NUM         打印NUM 行输出文本\n  -NUM                      same as --context&#x3D;NUM\n      --group-separator&#x3D;SEP use SEP as a group separator\n      --no-group-separator  use empty string as a group separator\n      --color[&#x3D;WHEN],\n      --colour[&#x3D;WHEN]       use markers to highlight the matching strings;\n                            WHEN is &#39;always&#39;, &#39;never&#39;, or &#39;auto&#39;\n  -U, --binary              do not strip CR characters at EOL (MSDOS&#x2F;Windows)\n\n常用参数:\n-v        取反\n-i        忽略大小写\n-c        符合条件的行数\n-n        输出的同时打印行号\n^*        以*开头         \n*$         以*结尾 \n^$         空行 \n\n-a        不忽略二进制数据\n-A&lt;n&gt;     除了显示匹配的行外，还显示之后的n行\n-b        在符合条件的行之前，显示该行第一个字符的编号\n\nDemo文案\n[root@Leonardo-iWzl-Aliyun-Service ~]# cat demo.log\nI came;\nI saw;\ni conquered.\n\n我来了，我看到了，我征服了.   ——凯撒大帝\n\n查找符合条件的行[root@Leonardo-iWzl-Aliyun-Service ~]# cat demo.log |grep &#39;I&#39;\nI came;\nI saw;\n\n查找符合条件的行数[root@Leonardo-iWzl-Aliyun-Service ~]# cat demo.log |grep &#39;I&#39; -c\n2\n\n查找不符合条件的行[root@Leonardo-iWzl-Aliyun-Service ~]# cat demo.log |grep &#39;I&#39; -v\ni conquered.\n\n我来了，我看到了，我征服了.   ——凯撒大帝\n\n忽略大小写查找[root@Leonardo-iWzl-Aliyun-Service ~]# cat demo.log |grep &#39;I&#39; -i\nI came;\nI saw;\ni conquered.\n\n查找符合条件的行并输出行号[root@Leonardo-iWzl-Aliyun-Service ~]# cat demo.log |grep &#39;I&#39; -n\n1:I came;\n2:I saw;\n\n以’*’开头的查询[root@Leonardo-iWzl-Aliyun-Service ~]# cat demo.log |grep &#39;^I&#39;\nI came;\nI saw;\n\n以’*’结尾的查询[root@Leonardo-iWzl-Aliyun-Service ~]# cat demo.log |grep &#39;; $&#39;\nI came;\nI saw;\n\n\nAwkAwk不仅仅是一个小工具，也可以算得上一种小型的编程语言了，支持if判断分支和while循环语句还有它的内置函数等，是一个要比grep和sed更强大的文本处理工具，但也就意味着要学习的东西更多了。由 Alfred Aho 、Peter Weinberger 和 Brian Kernighan 创始,并以姓氏的首个字母命名.\n基本结构和执行awk &#39;&#123;[pattern] action&#125;&#39; &#123;filenames&#125;  \nawk &#39;BEGIN&#123; commands &#125; pattern&#123; commands &#125; END&#123; commands &#125;&#39; &#123;filenames&#125;  \n\nAwk脚本通常由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块3部分组成，这三个部分是可选的。任意一个部分都可以不出现在脚本中，脚本通常是被单引号或双引号中.\n\n第一步：执行BEGIN{ commands }语句块中的语句；\n第二步：从文件或标准输入(stdin)读取一行，然后执行pattern{ commands }语句块，它逐行扫描文件，从第一行到最后一行重复这个过程，直到文件全部被读取完毕。\n第三步：当读至输入流末尾时，执行END{ commands }语句块。\n\nBEGIN语句块在awk开始从输入流中读取行之前被执行，这是一个可选的语句块，比如变量初始化、打印输出表格的表头等语句通常可以写在BEGIN语句块中。\nEND语句块在awk从输入流中读取完所有的行之后即被执行，比如打印所有行的分析结果这类信息汇总都是在END语句块中完成，它也是一个可选语句块。\nPattern语句块中的通用命令是最重要的部分，它也是可选的。如果没有提供pattern语句块，则默认执行{ print }，即打印每一个读取到的行，awk读取的每一行都会执行该语句块。\naction 在{}内指定，一般用来打印，也可以是一个代码段。也就是commands\n[root@Leonardo-iWzl-Server ~]# awk --help\nUsage: awk [POSIX or GNU style options] -f progfile [--] file ...\nUsage: awk [POSIX or GNU style options] [--] &#39;program&#39; file ...\nPOSIX options:\t\tGNU long options: (standard)\n\t-f progfile\t\t--file&#x3D;progfile\n\t-F fs\t\t\t--field-separator&#x3D;fs\n\t-v var&#x3D;val\t\t--assign&#x3D;var&#x3D;val\nShort options:\t\tGNU long options: (extensions)\n\t-b\t\t\t--characters-as-bytes\n\t-c\t\t\t--traditional\n\t-C\t\t\t--copyright\n\t-d[file]\t\t--dump-variables[&#x3D;file]\n\t-e &#39;program-text&#39;\t--source&#x3D;&#39;program-text&#39;\n\t-E file\t\t\t--exec&#x3D;file\n\t-g\t\t\t--gen-pot\n\t-h\t\t\t--help\n\t-L [fatal]\t\t--lint[&#x3D;fatal]\n\t-n\t\t\t--non-decimal-data\n\t-N\t\t\t--use-lc-numeric\n\t-O\t\t\t--optimize\n\t-p[file]\t\t--profile[&#x3D;file]\n\t-P\t\t\t--posix\n\t-r\t\t\t--re-interval\n\t-S\t\t\t--sandbox\n\t-t\t\t\t--lint-old\n\t-V\t\t\t--version\n\n内建参数\n\n\n变量\n描述\n\n\n\n$n\n当前记录的第n个字段，字段间由FS分隔\n\n\n$0\n完整的输入记录\n\n\nARGC\n命令行参数的数目\n\n\nARGIND\n命令行中当前文件的位置(从0开始算)\n\n\nARGV\n包含命令行参数的数组\n\n\nCONVFMT\n数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组\n\n\nERRNO\n最后一个系统错误的描述\n\n\nFIELDWIDTHS\n字段宽度列表(用空格键分隔)\n\n\nFILENAME\n当前文件名\n\n\nFNR\n各文件分别计数的行号\n\n\nFS\n字段分隔符(默认是任何空格)\n\n\nIGNORECASE\n如果为真，则进行忽略大小写的匹配\n\n\nNF\n一条记录的字段的数目\n\n\nNR\n已经读出的记录数，就是行号，从1开始\n\n\nOFMT\n数字的输出格式(默认值是%.6g)\n\n\nOFS\n输出记录分隔符（输出换行符），输出时用指定的符号代替换行符\n\n\nORS\n输出记录分隔符(默认值是一个换行符)\n\n\nRLENGTH\n由match函数所匹配的字符串的长度\n\n\nRS\n记录分隔符(默认是一个换行符)\n\n\nRSTART\n由match函数所匹配的字符串的第一个位置\n\n\nSUBSEP\n数组下标分隔符(默认值是/034)\n\n\n运算支持\n\n\n运算符\n描述\n\n\n\n= += -= *= /= %= ^= **=\n赋值\n\n\n?:\nC条件表达式\n\n\n||\n逻辑或\n\n\n&amp;&amp;\n逻辑与\n\n\n~ 和 !~\n匹配正则表达式和不匹配正则表达式\n\n\n&lt; &lt;= &gt; &gt;= != ==\n关系运算符\n\n\n空格\n连接\n\n\n+ -\n加，减\n\n\n* / %\n乘，除与求余\n\n\n+ - !\n一元加，减和逻辑非\n\n\n^ ***\n求幂\n\n\n++ –\n增加或减少，作为前缀或后缀\n\n\n$\n字段引用\n\n\nin\n数组成员\n\n\nDemo文案\n[root@Leonardo-iWzl-Server ~]# cat demo.log\n小米 20 成都 172 60 女\n小张 21 杭州 182 79 男\n小文 19 长沙 178 70 男\n小紫 22 北京 168 50 女\n\n输出指定位置的文档[root@Leonardo-iWzl-Server ~]# cat demo.log |awk &#39;&#123;print $1,$3,$5&#125;&#39;\n小米 成都 60\n小张 杭州 79\n小文 长沙 70\n小紫 北京 50\n\n指定分隔符输出文档# 使用&quot;1&quot;分割\n[root@Leonardo-iWzl-Server ~]# cat demo.log |awk -F 1 &#39;&#123;print $1&#125;&#39;\n小米 20 成都\n小张 2\n小文\n小紫 22 北京\n\n# 或者使用内建变量\n[root@Leonardo-iWzl-Server ~]# cat demo.log |awk &#39;BEGIN&#123;FS&#x3D;&#39;1&#39;&#125; &#123;print $1&#125;&#39;\n小米 20 成都\n小张 2\n小文\n小紫 22 北京\n\n# 使用多个分隔符.先使用&quot;1&quot;分割，然后对分割结果再使用&quot;0&quot;分割\n[root@Leonardo-iWzl-Server ~]# cat demo.log |awk -F &#39;[10]&#39; &#39;&#123;print $1&#125;&#39;\n小米 2\n小张 2\n小文\n小紫 22 北京\n\n# 或者使用内建变量\n[root@Leonardo-iWzl-Server ~]# cat demo.log |awk &#39;BEGIN&#123;FS&#x3D;&quot;[10]&quot;&#125; &#123;print $1&#125;&#39;\n小米 2\n小张 2\n小文\n小紫 22 北京\n\n设置计算参数并输出文档#awk -v 设置变量\n[root@Leonardo-iWzl-Server ~]# cat demo.log |awk -v a&#x3D;100 &#39;&#123;print $1,$2,a-$2&#125;&#39;\n小米 20 80\n小张 21 79\n小文 19 81\n小紫 22 78\n\n","slug":"历史文档/Liunx-Tips-001-Grep-Awk-Sed","date":"2020-08-14T03:45:29.000Z","categories_index":"Tips","tags_index":"Liunx,Tools,Shell","author_index":"王小妖"},{"id":"d416ce8c5d3763a84244c13dd056ecab","title":"Jenkins在CentOS系统环境上的搭建和部署","content":"Jenkins服务在CentOS系统环境上的搭建和部署\n\n\n\n\n\n\n\n\nJenkins 由Java编写的一个开源的、提供友好操作界面的持续集成(CI)工具，起源于Hudson（Hudson是商用的），主要用于持续、自动的构建/测试软件项目、监控外部任务的运行（这个比较抽象，暂且写上，不做解释）。Jenkins用Java语言编写，可在Tomcat等流行的servlet容器中运行，也可独立运行。通常与版本管理工具(SCM)、构建工具结合使用。常用的版本控制工具有SVN、GIT，构建工具有Maven、Ant、Gradle。\n  \n\nCI(Continuous integration，中文意思是持续集成)是一种软件开发时间。持续集成强调开发人员提交了新代码之后，立刻进行构建、（单元）测试。根据测试结果，我们可以确定新代码和原有代码能否正确地集成在一起。借用网络图片对CI加以理解。\n\n CD(Continuous Delivery， 中文意思持续交付)是在持续集成的基础上，将集成后的代码部署到更贴近真实运行环境(类生产环境)中。比如，我们完成单元测试后，可以把代码部署到连接数据库的Staging环境中更多的测试。如果代码没有问题，可以继续手动部署到生产环境。下图反应的是CI/CD 的大概工作模式。\n\n\n\n在线安装Jenkins# 获取 repo\n$ wget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;jenkins.repo https:&#x2F;&#x2F;pkg.jenkins.io&#x2F;redhat-stable&#x2F;jenkins.repo\n\n# 获取key, 如果之前导入 jenkins 的key, 这一步可以忽略\n$ rpm --import https:&#x2F;&#x2F;pkg.jenkins.io&#x2F;redhat-stable&#x2F;jenkins.io.key\n\n$ yum update &amp;&amp; yum install jenkins\n\n# 启用 jenkins\n$ systemctl start jenkins\n\n离线安装Jenkins# 准备安装临时文件夹\n$ mkdir jenkins\n$ cd jenkins\n\n# 获取最新的稳定版本的Jenkins.rpm文件(https:&#x2F;&#x2F;pkg.jenkins.io&#x2F;redhat-stable&#x2F;)\n$ wget https:&#x2F;&#x2F;pkg.jenkins.io&#x2F;redhat-stable&#x2F;jenkins-2.235.2-1.1.noarch.rpm\n\n# 执行本地的Yum安装\n$ yum localinstall jenkins-2.235.2-1.1.noarch.rpm\n\n# 启用 jenkins\n$ systemctl start jenkins\n\n安装异常解决异常信息如下[root@Leonardo-iWzl-Server jenkins]# systemctl start jenkins\nJob for jenkins.service failed because the control process exited with error code. See &quot;systemctl status jenkins.service&quot; and &quot;journalctl -xe&quot; for details.\n[root@Leonardo-iWzl-Server jenkins]# systemctl status jenkins\n● jenkins.service - LSB: Jenkins Automation Server\n   Loaded: loaded (&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;jenkins; bad; vendor preset: disabled)\n   Active: failed (Result: exit-code) since 四 2020-07-23 10:02:43 EDT; 16s ago\n     Docs: man:systemd-sysv-generator(8)\n  Process: 23582 ExecStart&#x3D;&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;jenkins start (code&#x3D;exited, status&#x3D;1&#x2F;FAILURE)\n\n7月 23 10:02:43 Leonardo-iWzl-Server systemd[1]: Starting LSB: Jenkins Automation Server...\n7月 23 10:02:43 Leonardo-iWzl-Server runuser[23587]: pam_unix(runuser:session): session opened for user jenkins...d&#x3D;0)\n7月 23 10:02:43 Leonardo-iWzl-Server jenkins[23582]: Starting Jenkins bash: &#x2F;usr&#x2F;bin&#x2F;java: No such file or directory\n7月 23 10:02:43 Leonardo-iWzl-Server runuser[23587]: pam_unix(runuser:session): session closed for user jenkins\n7月 23 10:02:43 Leonardo-iWzl-Server jenkins[23582]: [FAILED]\n7月 23 10:02:43 Leonardo-iWzl-Server systemd[1]: jenkins.service: control process exited, code&#x3D;exited status&#x3D;1\n7月 23 10:02:43 Leonardo-iWzl-Server systemd[1]: Failed to start LSB: Jenkins Automation Server.\n7月 23 10:02:43 Leonardo-iWzl-Server systemd[1]: Unit jenkins.service entered failed state.\n7月 23 10:02:43 Leonardo-iWzl-Server systemd[1]: jenkins.service failed.\nHint: Some lines were ellipsized, use -l to show in full.\n\n原因说明Jenkins 默认会在以下目录按顺序搜寻 JDK，一旦找到一个可用的即返回\n&#x2F;etc&#x2F;alternatives&#x2F;java\n&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-1.8.0&#x2F;bin&#x2F;java\n&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jre-1.8.0&#x2F;bin&#x2F;java\n&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-1.7.0&#x2F;bin&#x2F;java\n&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jre-1.7.0&#x2F;bin&#x2F;java\n&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-11.0&#x2F;bin&#x2F;java\n&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jre-11.0&#x2F;bin&#x2F;java\n&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-11-openjdk-amd64\n&#x2F;usr&#x2F;bin&#x2F;java\n\n如果系统的以上位置都未安装 JDK，启动时就会报错，可以通过建立软连接进行解决\nln -s &#x2F;usr&#x2F;local&#x2F;java&#x2F;jdk1.8.0_261&#x2F;bin&#x2F;java &#x2F;usr&#x2F;bin&#x2F;java\n\n完成以上错误处理后,可得到以下输出\n[root@Leonardo-iWzl-Server jenkins]# systemctl status jenkins\n● jenkins.service - LSB: Jenkins Automation Server\n   Loaded: loaded (&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;jenkins; bad; vendor preset: disabled)\n   Active: active (running) since 四 2020-07-23 10:10:06 EDT; 4s ago\n     Docs: man:systemd-sysv-generator(8)\n  Process: 23606 ExecStart&#x3D;&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;jenkins start (code&#x3D;exited, status&#x3D;0&#x2F;SUCCESS)\n   CGroup: &#x2F;system.slice&#x2F;jenkins.service\n           └─23630 &#x2F;usr&#x2F;bin&#x2F;java -Dcom.sun.akuma.Daemon&#x3D;daemonized -Djava.awt.headless&#x3D;true -DJENKINS_HOME&#x3D;&#x2F;var&#x2F;lib&#x2F;jenkins -jar &#x2F;usr&#x2F;lib&#x2F;jenkins&#x2F;jenkins.war --logfile&#x3D;&#x2F;var&#x2F;log&#x2F;jenkins&#x2F;jenkins.log --webroot&#x3D;&#x2F;var&#x2F;cache&#x2F;jenkins&#x2F;war --dae...\n\n7月 23 10:10:04 Leonardo-iWzl-Server systemd[1]: Starting LSB: Jenkins Automation Server...\n7月 23 10:10:04 Leonardo-iWzl-Server runuser[23611]: pam_unix(runuser:session): session opened for user jenkins by (uid&#x3D;0)\n7月 23 10:10:06 Leonardo-iWzl-Server runuser[23611]: pam_unix(runuser:session): session closed for user jenkins\n7月 23 10:10:06 Leonardo-iWzl-Server jenkins[23606]: Starting Jenkins [  OK  ]\n7月 23 10:10:06 Leonardo-iWzl-Server systemd[1]: Started LSB: Jenkins Automation Server.\n\n 查看jenkins 的启动参数 ps -ef |grep jenkins \n[root@Leonardo-iWzl-Server jenkins]# ps -ef |grep jenkins\njenkins  23630     1 49 10:10 ?        00:00:54 &#x2F;usr&#x2F;bin&#x2F;java \n\t\t-Dcom.sun.akuma.Daemon&#x3D;daemonized \n\t\t-Djava.awt.headless&#x3D;true \n\t\t-DJENKINS_HOME&#x3D;&#x2F;var&#x2F;lib&#x2F;jenkins \n\t\t-jar &#x2F;usr&#x2F;lib&#x2F;jenkins&#x2F;jenkins.war \n\t\t--logfile&#x3D;&#x2F;var&#x2F;log&#x2F;jenkins&#x2F;jenkins.log \n\t\t--webroot&#x3D;&#x2F;var&#x2F;cache&#x2F;jenkins&#x2F;war \n\t\t--daemon \n\t\t--httpPort&#x3D;8080 \n\t\t--debug&#x3D;5 \n\t\t--handlerCountMax&#x3D;100 \n\t\t--handlerCountMaxIdle&#x3D;20\nroot     23695 23312  0 10:11 pts&#x2F;0    00:00:00 grep --color&#x3D;auto jenkins\n\n在这里看到日志的一些配置和相关的端口、可以通过访问「IP」:8080访问到Jenkins服务\nJenkins的更新对于Jenkins更新可以通过\nyum update jenkins\n\n完成更新后,需要重启Jenkins服务\nJenkins国内镜像配置修改*/var/lib/jenkins* 目录下的hudson.model.UpdateCenter.xml文件内容如下\n&lt;?xml version='1.1' encoding='UTF-8'?>\n&lt;sites>\n  &lt;site>\n    &lt;id>default&lt;/id>\n    &lt;!-- &lt;url>https://updates.jenkins.io/update-center.json&lt;/url>-->\n     &lt;url>https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json/url>\n  &lt;/site>\n&lt;/sites>\n\n修改默认配置json文件*/var/lib/jenkins/updates/default.json*\n# 进入响应文件夹\ncd &#x2F;var&#x2F;lib&#x2F;jenkins&#x2F;updates\n\n# 备份原始文件\ncp default.json default.json.bak\n\n# 替换更新下载地址\nsed -i &#39;s&#x2F;http:\\&#x2F;\\&#x2F;updates.jenkins-ci.org\\&#x2F;download&#x2F;https:\\&#x2F;\\&#x2F;mirrors.tuna.tsinghua.edu.cn\\&#x2F;jenkins&#x2F;g&#39; default.json\n\n# 替换测试URL\nsed -i &#39;s&#x2F;http:\\&#x2F;\\&#x2F;www.google.com&#x2F;https:\\&#x2F;\\&#x2F;www.baidu.com&#x2F;g&#39; default.json\n\n完成以后重启Jenkins服务\n配置Jenkins服务之后按提示和Jenkins可视化引导完成剩余的Jenkins环境的搭建部署\nJenkins的结构导图\n\n参考和引用哥本哈根月光-Jenkins详细教程\nCentOS 安装 Jenkins 及 国内下载加速\n","slug":"历史文档/Jenkins-programming-environment-setup","date":"2020-07-23T13:32:40.000Z","categories_index":"DevOps","tags_index":"DevOps,Liunx,Jenkins,CentOS","author_index":"王小妖"},{"id":"27e755dac1a34d29a85efca0aec49e82","title":"Java Microbenchmark Harness微基准测试陷阱","content":"\n\n\n\n\n\n\n\n\n天下之事，闻者不如见者知之为详，见者不如居者知之为尽。——宋-陆游\n你要知道梨子的滋味，就要亲口尝一下。——毛泽东\n俗话说，没有实践就没有发言权，自己实践才能知之为尽，Benchmark 为应用提供了数据支持，是评价和比较方法好坏的基准，Benchmark 的准确性，多样性便显得尤为重要。JMH为Java方法的基准水平提供了很好的量化标准，也为剖析系统性能和技术选型提供的更为有效切可靠的实现手段。\n以下记录在使用Java Microbenchmark Harness做微基准测试容易遇见的误区和相关陷阱，便于之后的查找和说明。\n\n\n代码预热\n\n\n\n\n\n\n\n\nWarmup = waiting for the transient responses to settle down\n随着JVM虚拟机的优化，JIT的存在，代码的执行往往前期执行结果没有后期的执行结果好。 Benchmark 产生更可靠的结果的原因是，它只度量稳定状态下方法任务的执行时间，而不理会最初的性能。大多数 Java 实现具有复杂的性能生命周期。一般来说，最初的性能往往相当低，然后性能显著提高（常常出现几次性能跃升），直到到达稳定状态。\n类装载JVM 通常只在类的第一次使用类时装载它们。所以,方法任务的第一次执行时间包含装载它使用的所有类的时间（如果这些类还没有装载的话）。因为类装载往往涉及磁盘 I/O、解析和检验，这会显著增加方法任务的第一次执行时间。常常可以通过多次执行方法任务来消除这种影响。\n\n\n\n\n\n\n\n\n\nPS:  常常而不是总是，这是因为 方法任务 可能具有复杂的分支行为，这可能导致它在任何给定的执行过程中并不使用所有可能用到的类。幸运的是，如果执行任务足够多次，就可能经历所有分支，因此很快就会装载所有相关类）。\n如果使用定制的类装载器，就有另一个问题：JVM 可能认为一些类已经成了垃圾，因此决定卸载它。这不太可能严重影响性能，但是仍然会使基准测试结果产生偏差。\n混合模式在执行即时（Just-in-time，JIT）编译之前，现代的 JVM 通常会运行代码一段时间（常常是纯解释式运行），从而收集剖析信息。这对基准测试的影响在于，任务可能需要执行许多次，才能达到稳定状态。\n一般来说对稳定状态下的基准测试至少需要以下步骤：\n\n执行 方法任务 一次，以便装载所有类。\n执行 方法任务 足够多次，以确保出现稳定状态的执行数据。\n\n陷阱一: 死码消除死码消除(Dead code elimination）是一种编译最优化技术,在某些情况下，编译器可以判断出某些代码根本不影响输出，所以编译器会消除这些代码,例如注释的代码，不可达的代码块，可达但不被使用的代码，会被判断为死码而在Javac的时候被消除。\npublic class ErrorBenchmark &#123;\n    private double PI = Math.PI;\n  \n    @Benchmark\n    public void benchmarkNothing()&#123;\n        // 19873732.412 ± 6783114.266  ops/ms\n        //do nothing \n    &#125;\n  \n    @Benchmark\n    public void benchmarkWrong()&#123;\n        //  20988076.131 ± 7282548.202  ops/ms\n        Math.log(PI);  // DCE 会被判断为死码而被消除\n    &#125;\n\n    @Benchmark\n    public double benchmarkRight()&#123;\n       // 306740.041 ±   52692.696  ops/ms\n        return Math.log(PI);\n    &#125;\n\n&#125;\n\n在做测试时，需要注意方法会不会有死码的存在，否者可能会带来一些不合理的测试结果和意外。对于会被判断为死码但又需要进行执行测试方法来说，可以想办法去除孤立的方法执行，例如增加方法返回值，或者使用JMH的提供的APIBlackhole。\n@Benchmark\npublic void benchmarkRight(Blackhole bh) &#123;\n    bh.consume(Math.log(PI));\n&#125;\n\n陷阱二：常量折叠与常量传播常数折叠（Constant folding）以及常数传播（constant propagation）都是编译器最佳化技术。是一个在编译时期简化常数的一个过程。常数在表示式中仅仅代表一个简单的数值，就算一个变数从未被修改也可作为常数，或者直接将一个变数被明确地被标注为常数。\nlong number = 2 * 600 * 200;\n\n多数的现代编译器不会真的产生两个乘法的指令再将结果储存下来，取而代之的，他们会辨识出语句的结构，并在编译时期将数值直接计算出来。常数折叠的时机取决于编译器，有的在编译前期完成，有的在较后期进行。\nprivate double x = Math.PI;\n\n// 编译器会对 final 变量特殊处理 \nprivate final double wrongX = Math.PI;\n\n@Benchmark\npublic double baseline() &#123;\n    // 2.220 ± 0.352 ns/op\n    return Math.PI;\n&#125;\n\n@Benchmark\npublic double measureWrong_1() &#123; \n    // 2.220 ± 0.352 ns/op\n    // 错误，结果可以被预测，会发生常量折叠\n    return Math.log(Math.PI);\n&#125;\n\n@Benchmark\npublic double measureWrong_2() &#123; \n    // 2.220 ± 0.352 ns/op\n    // 错误，结果可以被预测，会发生常量折叠\n    return Math.log(wrongX);\n&#125;\n\n@Benchmark\npublic double measureRight() &#123; \n    // 22.590 ± 2.636  ns/op\n    return Math.log(x);\n&#125;\n\n由于发生了常量折叠，相同实现下的执行销量完全不同，这个测试在一定程度上说明了final的定义对于方法执行结果的影响。\n此外常数传播 (Constant propagation) 是一个替代表示式中已知常数的过程，也是在编译时期进行，包含前述所定义，内建函数也适用于常数。\nint x = 520;\nint y = 260 - 520 / 2;\nreturn y * (1314 / x + 2);\n\n传播可以理解变量的替换，如果进行持续传播，上式则可写成如下\nint x = 14;\nint y = 0;\nreturn 0;\n\n陷阱三：不要在测试中写循环为什么要使用JMH对于传统的接口调用测试，可能会使用以下的方式测试\nlong startTime = System.currentTimeMillis();\nbenchmarkTestMethod();\nSystem.out.println(System.currentTimeMillis()-startTime);\n\n而JMH则使用\n@Benchmark\npublic void benchmarkTestMethod()&#123;\n  // do \n&#125;\n\n\n参考和引用\nIBM Developer Java 代码基准测试的问题\nJAVA 拾遗 — JMH 与 8 个测试陷阱\n\n","slug":"历史文档/Java-Microbenchmark-Harness-Test-Trap","date":"2020-07-09T14:15:59.000Z","categories_index":"系统调优","tags_index":"Java,基准测试,系统调优,误区和陷阱,JMH","author_index":"王小妖"},{"id":"d3c057a0b9d8bdcf70200f0b91e6e914","title":"Java Microbenchmark Harness微基准测试基础","content":"\n\n\n\n\n\n\n\n\nIf you cannot measure it, you cannot improve it.    –Lord Kelvin\nJava Microbenchmark Harness 是专门进行代码的微基准测试的一套工具API。 为应用提供了数据支持，是评价和比较方法好坏的基准。一般说JMH，是在 Method 层面上的 Benchmark，精度可以精确到微秒级。以下记录JMH的使用和相关基础，便于之后查找和学习。\nBenchmark 作为应用框架，产品的基准画像，存在统一的标准，避免了不同测评对象自说自话的尴尬，应用框架各自使用有利于自身场景的测评方式必然不可取。\n\n\nHello JHMMaven依赖在项目中使用Maven,只需要添加如下依赖：\n&lt;!-- JMH-->\n&lt;dependency>\n    &lt;groupId>org.openjdk.jmh&lt;/groupId>\n    &lt;artifactId>jmh-core&lt;/artifactId>\n    &lt;version>$&#123;jmh.version&#125;&lt;/version>\n&lt;/dependency>\n&lt;dependency>\n    &lt;groupId>org.openjdk.jmh&lt;/groupId>\n    &lt;artifactId>jmh-generator-annprocess&lt;/artifactId>\n    &lt;version>$&#123;jmh.version&#125;&lt;/version>\n    &lt;scope>provided&lt;/scope>\n&lt;/dependency>\n\n性能测试设计测试比较Spring和StringBuilder的完成字符串拼接的性能\n/**\n * 比较字符串直接相加和StringBuilder的效率\n *\n * @author Leo Wang\n * @version 1.0\n * @date 2020/7/7 16:44\n */\n@BenchmarkMode(Mode.Throughput)\n@Warmup(iterations = 1,time = 1, timeUnit = TimeUnit.SECONDS)\n@Measurement(iterations = 10,time = 10,timeUnit = TimeUnit.SECONDS)\n@Threads(8)\n@Fork(2)\n@OutputTimeUnit(TimeUnit.MILLISECONDS)\n@State(Scope.Thread)\npublic class StringBuilderBenchmark &#123;\n    @Benchmark\n    public void testStringAdd() &#123;\n        String a = \"\";\n        for (int i = 0; i &lt; 10; i++) &#123;\n            a += i;\n        &#125;\n        print(a);\n    &#125;\n\n    @Benchmark\n    public void testStringBuilderAdd() &#123;\n        StringBuilder sb = new StringBuilder();\n        for (int i = 0; i &lt; 10; i++) &#123;\n            sb.append(i);\n        &#125;\n        print(sb.toString());\n    &#125;\n  \n    private void print(String a) &#123;\n    &#125;\n\n性能测试执行对于JMH来说，其执行方式主要有两种\n直接IDE运行对于体量小的测试，可以直接在IDE中完成相关的测试。如上的测试来说，可以直接运行，然后查看相关结果，执行的结果的Main函数如下，创建Options对象，传入需要执行的测试和测试报告的输出地址。直接执行Main方法\npublic static void main(String[] args) throws RunnerException &#123;\n    String userDirPath = System.getProperty(\"user.dir\");\n    String benchmarkLogPath = String.format(\"%s/%s\",userDirPath,\"/StringBenchmark.log\");\n    Options options = new OptionsBuilder()\n            .include(StringBuilderBenchmark.class.getSimpleName())\n            .output(benchmarkLogPath)\n            .build();\n    new Runner(options).run();\n&#125;\n\n在使用IDE进行测试时，需要注意不能使用Dubug模式启动，否则不能正常完成测试。\n打包成Jar,其他机器上执行一般对于大型的测试，需要测试时间比较久，线程比较多，就需要去写好了丢到远端的Linux系统环境中里执行， 不然会在本机执行很久并且需要的性能需求可能达不到测试需求。\nmvn clean package\njava -jar StringBuilderBenchmark.jar\n\n测试结果当正常跑完项目测试以后，JHM会在指定的文件夹下输出一下的测试结果\n# JMH version: 1.23\n# VM version: JDK 1.8.0_251, Java HotSpot(TM) 64-Bit Server VM, 25.251-b08\n# VM invoker: /Library/Java/JavaVirtualMachines/jdk1.8.0_251.jdk/Contents/Home/jre/bin/java\n# VM options: -javaagent:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar=63118:/Applications/IntelliJ IDEA.app/Contents/bin -Dfile.encoding=UTF-8\n# Warmup: 1 iterations, 1 s each\n# Measurement: 10 iterations, 10 s each\n# Timeout: 10 min per iteration\n# Threads: 8 threads, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: com.upuphub.lake.skylake.benchmark.StringBuilderBenchmark.testStringAdd\n\n# Run progress: 0.00% complete, ETA 00:06:44\n# Fork: 1 of 2\n# Warmup Iteration   1: 9014.340 ops/ms\nIteration   1: 21302.297 ops/ms\nIteration   2: 21807.763 ops/ms\nIteration   3: 21812.419 ops/ms\nIteration   4: 21840.912 ops/ms\nIteration   5: 21985.020 ops/ms\nIteration   6: 22066.751 ops/ms\nIteration   7: 22006.021 ops/ms\nIteration   8: 19239.509 ops/ms\nIteration   9: 10515.274 ops/ms\nIteration  10: 11758.987 ops/ms\n\n# Run progress: 25.00% complete, ETA 00:05:21\n# Fork: 2 of 2\n# Warmup Iteration   1: 5273.829 ops/ms\nIteration   1: 18880.356 ops/ms\nIteration   2: 22225.847 ops/ms\nIteration   3: 22017.665 ops/ms\nIteration   4: 22036.969 ops/ms\nIteration   5: 22080.422 ops/ms\nIteration   6: 22262.118 ops/ms\nIteration   7: 22153.187 ops/ms\nIteration   8: 22105.884 ops/ms\nIteration   9: 21613.504 ops/ms\nIteration  10: 22029.923 ops/ms\n\n\nResult \"com.upuphub.lake.skylake.benchmark.StringBuilderBenchmark.testStringAdd\":\n  20587.041 ±(99.9%) 2921.754 ops/ms [Average]\n  (min, avg, max) = (10515.274, 20587.041, 22262.118), stdev = 3364.697\n  CI (99.9%): [17665.287, 23508.796] (assumes normal distribution)\n\n\n# JMH version: 1.23\n# VM version: JDK 1.8.0_251, Java HotSpot(TM) 64-Bit Server VM, 25.251-b08\n# VM invoker: /Library/Java/JavaVirtualMachines/jdk1.8.0_251.jdk/Contents/Home/jre/bin/java\n# VM options: -javaagent:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar=63118:/Applications/IntelliJ IDEA.app/Contents/bin -Dfile.encoding=UTF-8\n# Warmup: 1 iterations, 1 s each\n# Measurement: 10 iterations, 10 s each\n# Timeout: 10 min per iteration\n# Threads: 8 threads, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: com.upuphub.lake.skylake.benchmark.StringBuilderBenchmark.testStringBuilderAdd\n\n# Run progress: 50.00% complete, ETA 00:03:34\n# Fork: 1 of 2\n# Warmup Iteration   1: 50084.373 ops/ms\nIteration   1: 67510.457 ops/ms\nIteration   2: 42202.643 ops/ms\nIteration   3: 41633.858 ops/ms\nIteration   4: 43352.405 ops/ms\nIteration   5: 43748.063 ops/ms\nIteration   6: 45176.476 ops/ms\nIteration   7: 44649.922 ops/ms\nIteration   8: 40872.340 ops/ms\nIteration   9: 40520.724 ops/ms\nIteration  10: 38853.095 ops/ms\n\n# Run progress: 75.00% complete, ETA 00:01:47\n# Fork: 2 of 2\n# Warmup Iteration   1: 45279.748 ops/ms\nIteration   1: 71985.226 ops/ms\nIteration   2: 43291.826 ops/ms\nIteration   3: 44149.181 ops/ms\nIteration   4: 43297.043 ops/ms\nIteration   5: 40614.460 ops/ms\nIteration   6: 40444.594 ops/ms\nIteration   7: 40912.490 ops/ms\nIteration   8: 41428.454 ops/ms\nIteration   9: 43022.557 ops/ms\nIteration  10: 43368.455 ops/ms\n\n\nResult \"com.upuphub.lake.skylake.benchmark.StringBuilderBenchmark.testStringBuilderAdd\":\n  45051.713 ±(99.9%) 7496.158 ops/ms [Average]\n  (min, avg, max) = (38853.095, 45051.713, 71985.226), stdev = 8632.587\n  CI (99.9%): [37555.555, 52547.872] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:07:08\n\nREMEMBER: The numbers below are just data. To gain reusable insights, you need to follow up on\nwhy the numbers are the way they are. Use profilers (see -prof, -lprof), design factorial\nexperiments, perform baseline and negative tests that provide experimental control, make sure\nthe benchmarking environment is safe on JVM/OS/HW level, ask for reviews from the domain experts.\nDo not assume the numbers tell you what you want them to tell.\n\nBenchmark                                     Mode  Cnt      Score      Error   Units\nStringBuilderBenchmark.testStringAdd         thrpt   20  20587.041 ± 2921.754  ops/ms\nStringBuilderBenchmark.testStringBuilderAdd  thrpt   20  45051.713 ± 7496.158  ops/ms\n\n整个测试报告由三个部分组成，首先分别是testStringAdd的测试结果然后是testStringBuilderAdd的测试结果，最后时两个测试结果之间的结果汇总和对应的比较。前两个部分的结果是类似的，会列出测试环境的一些基本信息，包括JHM的版本、虚拟机版本和相关一些配置等的信息以及测试的一些配置和设置，然后就是预热迭代执行（Warmup Iteration）， 然后是正常的迭代执行（Iteration），最后是结果（Result）的信息输出。一般来说最关注第三部分，也就是汇总结果。\n\n\n\n\n\n\n\n\n\nTips: 对于汇总结果部分的输出,Error是没有数据的，这里是Score过长挤过去的\n可以看出StringBuilder在做字符串拼接的速度比String的直接评价速度好两倍以上。\nJHM的注解和功能@BenchmarkMode基准测试类型。这里选择的是Throughput也就是吞吐量。吞吐量会得到单位时间内可以进行的操作数。\n\nThroughput: 整体吞吐量，例如“1秒内可以执行多少次调用”。\nAverageTime: 调用的平均时间，例如“每次调用平均耗时xxx毫秒”。\nSampleTime: 随机取样，最后输出取样结果的分布，例如“99%的调用在xxx毫秒以内，99.99%的调用在xxx毫秒以内”\nSingleShotTime: 以上模式都是默认一次 iteration 是 1s，唯有 SingleShotTime 是只运行一次。往往同时把 warmup 次数设为0，用于测试冷启动时的性能。\nAll(“all”, “All benchmark modes”): 执行所有模式。\n\n@Warmup在进行基准测试前需要进行预热。一般前几次进行程序测试的时候都会比较慢， 所以要让程序进行几轮预热，保证测试的准确性。其中的参数iterations就是预热轮数。\n\n\n\n\n\n\n\n\n\nTips: 因为 JVM 的 JIT 机制的存在，如果某个函数被调用多次之后，JVM 会尝试将其编译成为机器码从而提高执行速度。所以为了让 benchmark 的结果更加接近真实情况就需要进行预热\n@Measurement度量，一些基本的测试参数。\n\niterations 进行测试的轮次\ntime 每轮进行的时长\ntimeUnit 时长单位\n\n可以根据具体情况调整。一般比较重的东西可以进行大量的测试，放到服务器上运行。\n@Threads每个进程中的测试线程，根据具体情况选择，一般为cpu乘以2。\n@Fork进行 fork 的次数。如果 fork 数是2的话，则 JMH 会 fork 出两个进程来进行测试。\n@OutputTimeUnit基准测试结果的时间类型。一般选择秒、毫秒、微秒。\n@Benchmark方法级注解，表示该方法是需要进行 benchmark ，用法和 JUnit 的 @Test 类似。\n@Param属性级注解，@Param 用来指定某项参数的多种情况。适合用来测试一个函数在不同的参数输入的情况下的性能。\n@Setup方法级注解，需要在测试之前进行一些准备工作，比如对一些数据的初始化。\n@TearDown方法级注解，在测试之后进行一些结束工作，比如关闭线程池，数据库连接等的，主要用于资源的回收等。\n@State当使用@Setup参数的时候，必须在类上加这个参数，不然会提示无法运行。\nState 用于声明某个类是一个“状态”，然后接受一个 Scope 参数用来表示该状态的共享范围。 很多 benchmark 会需要一些表示状态的类，JMH 允许你把这些类以依赖注入的方式注入到 benchmark 函数里。Scope 主要分为三种。\n\nThread: 该状态为每个线程独享。\nGroup: 该状态为同一个组里面所有线程共享。\nBenchmark: 该状态在所有线程间共享。\n\n补充说明在日常的工作和学习中，常常会遇到三种类型的问题，JHM对其能很好就觉很处理。\n\n对方法或库的不同实现方式的性能分析测试和最后的采用取舍\n方法入参对方法的性能影响和限制\n对项目中的热点方法的优化和其优化效果的定性分析。\n\n\n参考和来源\nJava微基准测试框架JMH\nJava使用JMH进行简单的基准测试Benchmark\nJava 并发编程笔记：JMH 性能测试框架\nJMH - Java Microbenchmark Harness\n\n","slug":"历史文档/Java-Microbenchmark-Harness-Basic","date":"2020-07-07T10:24:35.000Z","categories_index":"系统调优","tags_index":"Java,基准测试,系统调优,JMH,基础","author_index":"王小妖"},{"id":"104a9aae1e5de115cd62851ef23d3bb9","title":"CentOS下Nginx支持SSL协议的编译安装","content":"Nginx及其衍生的其他相关优秀开源产品\nNGINX 是开源、高性能、高可靠的 Web 和反向代理服务器\nTengine Tengine是由淘宝网发起基于Nginx的Web服务器项目\nOpenResty OpenResty® 是一个基于 Nginx 与 Lua 的高性能 Web 平台\n\n下载Nginx稳定版包并解压wget http://nginx.org/download/nginx-x.x.x.tar.gz\ntar zxvf nginx-x.x.x.tar.gz\ncd nginx-x.x.x\n\n\n补全需要的库依赖yum install gcc-c++\nyum install -y pcre pcre-devel\nyum install -y zlib zlib-devel\nyum install -y openssl openssl-devel\n\n执行编译安装所有文件放在同一个位置,便于统一管理\n./configure --prefix=/usr/local/nginx  \\\n--conf-path=/usr/local/nginx/etc/nginx.conf  \\\n--user=nginx --group=nginx  \\\n--error-log-path=/usr/local/nginx/nginxlog/error.log  \\\n--http-log-path=/usr/local/nginx/nginxlog/access.log  \\\n--pid-path=/usr/local/nginx/pids/nginx.pid  \\\n--lock-path=/usr/local/nginx/locks/nginx.lock  \\\n--with-http_ssl_module  \\\n--with-http_stub_status_module  \\\n--with-http_gzip_static_module  \\\n--http-client-body-temp-path=/usr/local/nginx/tmp/client  \\\n--http-proxy-temp-path=/usr/local/nginx/tmp/proxy  \\\n--http-fastcgi-temp-path=/usr/local/nginx/tmp/fastcgi  \\\n--http-uwsgi-temp-path=/usr/local/nginx/tmp/uwsgi  \\\n--http-scgi-temp-path=/usr/local/nginx/tmp/scgi\n编译结果\nConfiguration summary\n  + using system PCRE library\n  + using system OpenSSL library\n  + using system zlib library\n\n  nginx path prefix: \"/usr/local/nginx\"\n  nginx binary file: \"/usr/local/nginx/sbin/nginx\"\n  nginx modules path: \"/usr/local/nginx/modules\"\n  nginx configuration prefix: \"/usr/local/nginx/etc\"\n  nginx configuration file: \"/usr/local/nginx/etc/nginx.conf\"\n  nginx pid file: \"/usr/local/nginx/pids/nginx.pid\"\n  nginx error log file: \"/usr/local/nginx/nginxlog/error.log\"\n  nginx http access log file: \"/usr/local/nginx/nginxlog/access.log\"\n  nginx http client request body temporary files: \"/usr/local/nginx/tmp/client\"\n  nginx http proxy temporary files: \"/usr/local/nginx/tmp/proxy\"\n  nginx http fastcgi temporary files: \"/usr/local/nginx/tmp/fastcgi\"\n  nginx http uwsgi temporary files: \"/usr/local/nginx/tmp/uwsgi\"\n  nginx http scgi temporary files: \"/usr/local/nginx/tmp/scgi\n执行安装\nmake &amp;&amp; make install\n安装后处理查看文件结构\ncd /usr/local/nginx/\ntree\n.\n├── etc\n│   ├── fastcgi.conf\n│   ├── fastcgi.conf.default\n│   ├── fastcgi_params\n│   ├── fastcgi_params.default\n│   ├── koi-utf\n│   ├── koi-win\n│   ├── mime.types\n│   ├── mime.types.default\n│   ├── nginx.conf\n│   ├── nginx.conf.default\n│   ├── scgi_params\n│   ├── scgi_params.default\n│   ├── uwsgi_params\n│   ├── uwsgi_params.default\n│   └── win-utf\n├── html\n│   ├── 50x.html\n│   └── index.html\n├── nginxlog\n├── pids\n└── sbin\n    └── nginx\n完善Nginx目录结构\nmkdir -pv /usr/local/nginx/tmp/&#123;client,proxy,fastcgi,uwsgi,scgi&#125;\nNginx启动和监听# 启动\n/usr/local/nginx/sbin/nginx\n# 检查是否启动\nss -tnlp | grep :80","slug":"历史文档/Nginx-under-CentOS-installation","date":"2020-07-04T10:24:35.000Z","categories_index":"Nginx","tags_index":"Liunx,CentOS,Nginx,Server","author_index":"王小妖"}]